{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os, time, random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Callable, List\n",
    "from functools import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = Path('.').absolute()\n",
    "data_dir=cur_dir.parent/ 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/tag.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/movie.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/link.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/rating.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/movies.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/genome_tags.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/genome_scores.csv')]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Movie df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv(data_dir/'movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27278 entries, 0 to 27277\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  27278 non-null  int64 \n",
      " 1   title    27278 non-null  object\n",
      " 2   genres   27278 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 639.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId    0\n",
       "title      0\n",
       "genres     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.isna().sum() # no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.duplicated().sum() #no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27262"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aladdin (1992)', 'Johnny Express (2014)', 'Chaos (2005)', 'Hamlet (2000)', '20,000 Leagues Under the Sea (1997)', 'Darling (2007)', 'Casanova (2005)', 'Paradise (2013)', 'Beneath (2013)', 'Girl, The (2012)', 'Clear History (2013)', 'Emma (1996)', 'Offside (2006)', 'Blackout (2007)', 'Men with Guns (1997)', 'War of the Worlds (2005)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the value counts for each movie title\n",
    "title_value_counts = movie_df['title'].value_counts()\n",
    "\n",
    "# Filter titles that appear more than once\n",
    "duplicate_titles = title_value_counts[title_value_counts > 1].index.tolist()\n",
    "\n",
    "print(duplicate_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some movies have multiple entries with different `movieid` , but it doesn't affect much "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so in genres column there seems to have no spaces bw genres, lets see want unique genres as there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = movie_df.genres.apply(lambda x : ' '.join(str(x).split('|'))).values.tolist() # split from |\n",
    "all_genres = ' '.join(set(all_genres)).split() # join all strings and break them into words\n",
    "all_genres = set(all_genres)  # make a set to find unique ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Thriller', 'Drama', 'listed)', 'War', 'Animation', 'Fantasy', 'Documentary', 'Crime', 'Action', 'IMAX', 'Romance', 'Western', 'Musical', 'Children', 'Comedy', 'genres', 'Sci-Fi', 'Adventure', '(no', 'Film-Noir', 'Horror', 'Mystery'} 22\n"
     ]
    }
   ],
   "source": [
    "print(all_genres, len(all_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 20 genres and 1 for movies with no genre (which is (no listed)) which is broken as '(no' and 'listed)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a tag columns that contains all information about movie in a sentence\n",
    "movie_df['tags'] = movie_df['title'] + ' ' + movie_df['genres'].apply(lambda x: ' '.join(str(x).split('|')))\n",
    "movie_df['tags'] = movie_df['tags'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_df['Title'] = movie_df.title.apply(lambda x : str(x).split('(')[0])\n",
    "# movie_df['Year'] = movie_df.title.apply(lambda x : (str(x).split('(')[-1]).strip(')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>2059</td>\n",
       "      <td>Parent Trap, The (1998)</td>\n",
       "      <td>Children|Comedy|Romance</td>\n",
       "      <td>parent trap, the (1998) children comedy romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22506</th>\n",
       "      <td>107914</td>\n",
       "      <td>Fade To Black (1980)</td>\n",
       "      <td>Comedy|Horror|Thriller</td>\n",
       "      <td>fade to black (1980) comedy horror thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>4735</td>\n",
       "      <td>Ghosts of Mars (2001)</td>\n",
       "      <td>Horror|Sci-Fi|Thriller</td>\n",
       "      <td>ghosts of mars (2001) horror sci-fi thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17760</th>\n",
       "      <td>89230</td>\n",
       "      <td>Tooth &amp; Nail (2007)</td>\n",
       "      <td>Drama|Horror|Sci-Fi</td>\n",
       "      <td>tooth &amp; nail (2007) drama horror sci-fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>96923</td>\n",
       "      <td>2-Headed Shark Attack (2012)</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "      <td>2-headed shark attack (2012) comedy horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>3906</td>\n",
       "      <td>Under Suspicion (2000)</td>\n",
       "      <td>Crime|Thriller</td>\n",
       "      <td>under suspicion (2000) crime thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7960</th>\n",
       "      <td>8643</td>\n",
       "      <td>Cinderella Story, A (2004)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>cinderella story, a (2004) comedy romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26956</th>\n",
       "      <td>129532</td>\n",
       "      <td>Island (2011)</td>\n",
       "      <td>Drama|Mystery|Thriller</td>\n",
       "      <td>island (2011) drama mystery thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236</th>\n",
       "      <td>131122</td>\n",
       "      <td>Love Exposure (2007)</td>\n",
       "      <td>Action|Comedy|Drama|Romance</td>\n",
       "      <td>love exposure (2007) action comedy drama romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>3012</td>\n",
       "      <td>Battling Butler (1926)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>battling butler (1926) comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7826</th>\n",
       "      <td>8458</td>\n",
       "      <td>To Each His Own (1946)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>to each his own (1946) drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17435</th>\n",
       "      <td>87917</td>\n",
       "      <td>Swamp Water (1941)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>swamp water (1941) drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>52781</td>\n",
       "      <td>Hana (Hana yori mo naho) (2006)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>hana (hana yori mo naho) (2006) comedy drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14553</th>\n",
       "      <td>72850</td>\n",
       "      <td>My Friend Ivan Lapshin (Moy drug Ivan Lapshin)...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>my friend ivan lapshin (moy drug ivan lapshin)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22722</th>\n",
       "      <td>108780</td>\n",
       "      <td>Labor Day (2013)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>labor day (2013) drama romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20549</th>\n",
       "      <td>100579</td>\n",
       "      <td>Universal Soldier: Day of Reckoning (2012)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>universal soldier: day of reckoning (2012) act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25891</th>\n",
       "      <td>122950</td>\n",
       "      <td>Mare Nostrum (1926)</td>\n",
       "      <td>War</td>\n",
       "      <td>mare nostrum (1926) war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16845</th>\n",
       "      <td>85211</td>\n",
       "      <td>Norwegian Wood (Noruwei no mori) (2010)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>norwegian wood (noruwei no mori) (2010) drama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20222</th>\n",
       "      <td>99521</td>\n",
       "      <td>Incruste, L' (a.k.a. L'Incruste, fallait pas l...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>incruste, l' (a.k.a. l'incruste, fallait pas l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20175</th>\n",
       "      <td>99337</td>\n",
       "      <td>Foreign Intrigue (1956)</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>foreign intrigue (1956) thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11344</th>\n",
       "      <td>48315</td>\n",
       "      <td>Raintree County (1957)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>raintree county (1957) drama romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22679</th>\n",
       "      <td>108583</td>\n",
       "      <td>Fawlty Towers (1975-1979)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>fawlty towers (1975-1979) comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                              title  \\\n",
       "1975      2059                            Parent Trap, The (1998)   \n",
       "22506   107914                               Fade To Black (1980)   \n",
       "4639      4735                              Ghosts of Mars (2001)   \n",
       "17760    89230                                Tooth & Nail (2007)   \n",
       "19572    96923                       2-Headed Shark Attack (2012)   \n",
       "3813      3906                             Under Suspicion (2000)   \n",
       "7960      8643                         Cinderella Story, A (2004)   \n",
       "26956   129532                                      Island (2011)   \n",
       "27236   131122                               Love Exposure (2007)   \n",
       "2926      3012                             Battling Butler (1926)   \n",
       "7826      8458                             To Each His Own (1946)   \n",
       "17435    87917                                 Swamp Water (1941)   \n",
       "11832    52781                    Hana (Hana yori mo naho) (2006)   \n",
       "14553    72850  My Friend Ivan Lapshin (Moy drug Ivan Lapshin)...   \n",
       "22722   108780                                   Labor Day (2013)   \n",
       "20549   100579         Universal Soldier: Day of Reckoning (2012)   \n",
       "25891   122950                                Mare Nostrum (1926)   \n",
       "16845    85211            Norwegian Wood (Noruwei no mori) (2010)   \n",
       "20222    99521  Incruste, L' (a.k.a. L'Incruste, fallait pas l...   \n",
       "20175    99337                            Foreign Intrigue (1956)   \n",
       "11344    48315                             Raintree County (1957)   \n",
       "22679   108583                          Fawlty Towers (1975-1979)   \n",
       "\n",
       "                            genres  \\\n",
       "1975       Children|Comedy|Romance   \n",
       "22506       Comedy|Horror|Thriller   \n",
       "4639        Horror|Sci-Fi|Thriller   \n",
       "17760          Drama|Horror|Sci-Fi   \n",
       "19572                Comedy|Horror   \n",
       "3813                Crime|Thriller   \n",
       "7960                Comedy|Romance   \n",
       "26956       Drama|Mystery|Thriller   \n",
       "27236  Action|Comedy|Drama|Romance   \n",
       "2926                        Comedy   \n",
       "7826                         Drama   \n",
       "17435                        Drama   \n",
       "11832                 Comedy|Drama   \n",
       "14553                        Drama   \n",
       "22722                Drama|Romance   \n",
       "20549       Action|Sci-Fi|Thriller   \n",
       "25891                          War   \n",
       "16845                Drama|Romance   \n",
       "20222                       Comedy   \n",
       "20175                     Thriller   \n",
       "11344                Drama|Romance   \n",
       "22679                       Comedy   \n",
       "\n",
       "                                                    tags  \n",
       "1975     parent trap, the (1998) children comedy romance  \n",
       "22506        fade to black (1980) comedy horror thriller  \n",
       "4639        ghosts of mars (2001) horror sci-fi thriller  \n",
       "17760            tooth & nail (2007) drama horror sci-fi  \n",
       "19572         2-headed shark attack (2012) comedy horror  \n",
       "3813               under suspicion (2000) crime thriller  \n",
       "7960           cinderella story, a (2004) comedy romance  \n",
       "26956               island (2011) drama mystery thriller  \n",
       "27236   love exposure (2007) action comedy drama romance  \n",
       "2926                       battling butler (1926) comedy  \n",
       "7826                        to each his own (1946) drama  \n",
       "17435                           swamp water (1941) drama  \n",
       "11832       hana (hana yori mo naho) (2006) comedy drama  \n",
       "14553  my friend ivan lapshin (moy drug ivan lapshin)...  \n",
       "22722                     labor day (2013) drama romance  \n",
       "20549  universal soldier: day of reckoning (2012) act...  \n",
       "25891                            mare nostrum (1926) war  \n",
       "16845  norwegian wood (noruwei no mori) (2010) drama ...  \n",
       "20222  incruste, l' (a.k.a. l'incruste, fallait pas l...  \n",
       "20175                   foreign intrigue (1956) thriller  \n",
       "11344               raintree county (1957) drama romance  \n",
       "22679                   fawlty towers (1975-1979) comedy  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.sample(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploraing User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(data_dir/'rating.csv', usecols=['userId','movieId','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 1, 138493)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this columns are using too much precision for very low values, lowering the datatype precision\n",
    "user_df['movieId'] = user_df['movieId'].astype('int32')\n",
    "user_df['userId'] = user_df['userId'].astype('int32')\n",
    "user_df['rating'] = user_df['rating'].astype('float32')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 1, 138493)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000263, 3)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape #(20000263,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   userId   int32  \n",
      " 1   movieId  int32  \n",
      " 2   rating   float32\n",
      "dtypes: float32(1), int32(2)\n",
      "memory usage: 228.9 MB\n"
     ]
    }
   ],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        2     3.5\n",
       "1       1       29     3.5\n",
       "2       1       32     3.5\n",
       "3       1       47     3.5\n",
       "4       1       50     3.5"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x: str) -> str:\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)  # Remove punctuation\n",
    "    x = x.lower()  # Convert to lowercase\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, special_tokens: List[str]):\n",
    "        self.word_to_idx = {}\n",
    "        self.idx_to_word = {}\n",
    "        self.counter = Counter()\n",
    "        \n",
    "        self.UNK_TOKEN = '<UNK>'\n",
    "        self.UNK = 1\n",
    "        self.PAD_TOKEN = '<PAD>'\n",
    "        self.PAD = 0\n",
    "        \n",
    "        self.word_to_idx[self.UNK_TOKEN] = self.UNK\n",
    "        self.idx_to_word[self.UNK] = self.UNK_TOKEN\n",
    "\n",
    "        self.word_to_idx[self.PAD_TOKEN] = self.PAD\n",
    "        self.idx_to_word[self.PAD] = self.PAD_TOKEN\n",
    "\n",
    "        self.vocab_size = 2\n",
    "        for idx, token in enumerate(special_tokens, start=2):\n",
    "            self.word_to_idx[token] = idx\n",
    "            self.idx_to_word[idx] = token\n",
    "            self.vocab_size += 1\n",
    "\n",
    "    def build_vocab(self, tokenized_data, max_tokens, min_freq):\n",
    "        self.counter = Counter()\n",
    "        for words in tokenized_data:\n",
    "            self.counter.update(words)\n",
    "\n",
    "        if max_tokens is not None:\n",
    "            sorted_tokens = [word for word, _ in self.counter.most_common()]\n",
    "            for word in sorted_tokens:\n",
    "                if word not in self.word_to_idx:\n",
    "                    self.add_word_to_vocab(word)\n",
    "\n",
    "                if self.vocab_size == max_tokens - 1:\n",
    "                    break\n",
    "        else:\n",
    "            for word, freq in self.counter.items():\n",
    "                if freq >= min_freq and word not in self.word_to_idx:\n",
    "                    self.add_word_to_vocab(word)\n",
    "\n",
    "    def add_word_to_vocab(self, word):\n",
    "        self.word_to_idx[word] = self.vocab_size\n",
    "        self.idx_to_word[self.vocab_size] = word\n",
    "        self.vocab_size += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class IntegerVectorizer:\n",
    "    def __init__(self, \n",
    "                 tokenizer: Callable[[str], List[str]] = None,\n",
    "                 preprocessing_func: Callable[[str], str] = None,\n",
    "                 max_tokens=None,\n",
    "                 min_freq=1,\n",
    "                 special_tokens: List[str] = None,\n",
    "                 max_seq_length=None,\n",
    "                 pad_to_max=False):\n",
    "        \n",
    "        self.min_freq = min_freq\n",
    "        self.max_tokens = max_tokens\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        self.reserved_tokens = ['<UNK>', '<PAD>']\n",
    "        self.special_tokens = [token for token in special_tokens if token not in self.reserved_tokens] if special_tokens else []\n",
    "        self.pad_to_max = pad_to_max  # Store the argument\n",
    "\n",
    "        self.vocab = Vocabulary(self.special_tokens)\n",
    "        self.tokenized_data = []\n",
    "\n",
    "    def adapt(self, data):\n",
    "        self.tokenized_data = self.tokenize_data_generator(data)\n",
    "        self.vocab.build_vocab(self.tokenized_data, self.max_tokens, self.min_freq)\n",
    "        print('Vocab size:', len(self.vocab))\n",
    "\n",
    "    def __call__(self, data, reverse=False):\n",
    "        if reverse:\n",
    "            return self.reverse_transform(data)\n",
    "        else:\n",
    "            return self.transform(data)\n",
    "\n",
    "    def preprocess_sentence(self, sentence):\n",
    "        if self.preprocessing_func:\n",
    "            words = sentence.split()\n",
    "            preprocessed_words = [self.preprocessing_func(word) if word not in self.special_tokens else word for word in words]\n",
    "            return \" \".join(preprocessed_words)\n",
    "        return sentence\n",
    "\n",
    "    def tokenize_data_generator(self, data):\n",
    "        for sentence in data:\n",
    "            sentence = self.preprocess_sentence(sentence)\n",
    "            words = self.tokenizer(sentence) if self.tokenizer else sentence.split()\n",
    "            yield words\n",
    "\n",
    "    def transform(self, data):\n",
    "        self.tokenized_data = self.tokenize_data_generator(data)\n",
    "        vectorized_data = []\n",
    "        for sentence in self.tokenized_data:\n",
    "            vectorized_sentence = [self.vocab.word_to_idx.get(word, self.vocab.UNK) for word in sentence]\n",
    "            vectorized_sentence = self.adjust_sequence_length(vectorized_sentence)\n",
    "            vectorized_data.append(vectorized_sentence)\n",
    "        return vectorized_data\n",
    "\n",
    "    def adjust_sequence_length(self, sequence):\n",
    "        if self.max_seq_length is not None:\n",
    "            if len(sequence) < self.max_seq_length:\n",
    "                if self.pad_to_max:  # Check the new argument\n",
    "                    sequence += [self.vocab.PAD] * (self.max_seq_length - len(sequence))\n",
    "            elif len(sequence) > self.max_seq_length:\n",
    "                sequence = sequence[:self.max_seq_length]\n",
    "        return sequence\n",
    "\n",
    "\n",
    "    def reverse_transform(self, vectorized_data: List[List[int]]) -> List[str]:\n",
    "        original_data = []\n",
    "        for vector in vectorized_data:\n",
    "            sentence = [self.vocab.idx_to_word[idx] for idx in vector if idx != self.vocab.PAD]\n",
    "            original_data.append(\" \".join(sentence))\n",
    "        return original_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 13\n",
      "Original data: ['This is a sample sentence. <UNK>', '<START> Another example sentence. <END>', '<START> This is another sentence. <END>', '3 3 3 3 3 3 ']\n",
      "Vectorized data: [[2, 3, 4, 5, 6, 1], [7, 8, 9, 6, 10], [7, 2, 3, 11, 6, 10], [12, 12, 12, 12, 12, 12]]\n",
      "reverse vec:  ['This is a sample sentence. <UNK>', '<START> Another example sentence. <END>', '<START> This is another sentence. <END>', '3 3 3 3 3 3']\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    \"This is a sample sentence. <UNK>\",\n",
    "    \"<START> Another example sentence. <END>\",\n",
    "    \"<START> This is another sentence. <END>\",\n",
    "    '3 3 3 3 3 3 '\n",
    "]\n",
    "min_freq = 2\n",
    "max_tokens = None\n",
    "special_tokens = ['<START>', '<END>', '<UNK>','<PAD>']\n",
    "\n",
    "\n",
    "vectorizer = IntegerVectorizer(max_seq_length=10, pad_to_max=False)\n",
    "vectorizer.adapt(data)\n",
    "a = vectorizer(data)\n",
    "b = vectorizer.reverse_transform(a)\n",
    "\n",
    "\n",
    "print(\"Original data:\", data)\n",
    "print(\"Vectorized data:\", a)\n",
    "print('reverse vec: ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 29464\n"
     ]
    }
   ],
   "source": [
    "#adapt to data\n",
    "vectorizer = IntegerVectorizer(max_seq_length=15, pad_to_max=True)\n",
    "vectorizer.adapt(movie_df['tags'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df['tagvector'] = movie_df['tags'].apply(lambda x : vectorizer.transform([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>tags</th>\n",
       "      <th>tagvector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>toy story (1995) adventure animation children ...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>jumanji (1995) adventure children fantasy</td>\n",
       "      <td>[10, 4, 5, 7, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>grumpier old men (1995) comedy romance</td>\n",
       "      <td>[11, 12, 13, 4, 8, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>waiting to exhale (1995) comedy drama romance</td>\n",
       "      <td>[15, 16, 17, 4, 8, 18, 14, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>father of the bride part ii (1995) comedy</td>\n",
       "      <td>[19, 20, 21, 22, 23, 24, 4, 8, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1                   Adventure|Children|Fantasy   \n",
       "2                               Comedy|Romance   \n",
       "3                         Comedy|Drama|Romance   \n",
       "4                                       Comedy   \n",
       "\n",
       "                                                tags  \\\n",
       "0  toy story (1995) adventure animation children ...   \n",
       "1          jumanji (1995) adventure children fantasy   \n",
       "2             grumpier old men (1995) comedy romance   \n",
       "3      waiting to exhale (1995) comedy drama romance   \n",
       "4          father of the bride part ii (1995) comedy   \n",
       "\n",
       "                                           tagvector  \n",
       "0      [2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1     [10, 4, 5, 7, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2  [11, 12, 13, 4, 8, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [15, 16, 17, 4, 8, 18, 14, 0, 0, 0, 0, 0, 0, 0...  \n",
       "4  [19, 20, 21, 22, 23, 24, 4, 8, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       user_df: 228.9 MiB\n",
      "                      movie_df: 11.6 MiB\n",
      "            title_value_counts:  2.5 MiB\n",
      "                           _47:  6.0 KiB\n",
      "                          _156:  5.8 KiB\n",
      "                           _17:  5.7 KiB\n",
      "                           _60:  3.7 KiB\n",
      "                          _i28:  3.0 KiB\n",
      "                          _i55:  3.0 KiB\n",
      "                         _i166:  3.0 KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix=\"B\"):\n",
    "    \n",
    "    \"\"\"by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified\"\"\"\n",
    "    for unit in [\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\", \"Pi\", \"Ei\", \"Zi\"]:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, \"Yi\", suffix)\n",
    "    \n",
    "\n",
    "for name, size in sorted(\n",
    "    ((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "    key=lambda x: -x[1],\n",
    ")[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = user_df.merge(movie_df[['movieId','tagvector']], on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>tagvector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2697298</th>\n",
       "      <td>29690</td>\n",
       "      <td>908</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[1042, 174, 1831, 1362, 26, 5, 62, 14, 28, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333591</th>\n",
       "      <td>23485</td>\n",
       "      <td>296</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[669, 670, 137, 8, 27, 18, 28, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156508</th>\n",
       "      <td>96952</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[36, 37, 21, 4, 8, 18, 14, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118945</th>\n",
       "      <td>58170</td>\n",
       "      <td>6711</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[74, 156, 8729, 7897, 8, 18, 14, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295194</th>\n",
       "      <td>559</td>\n",
       "      <td>1183</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2257, 2258, 21, 159, 18, 14, 115, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580390</th>\n",
       "      <td>110846</td>\n",
       "      <td>3147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[702, 4665, 21, 2984, 27, 18, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591774</th>\n",
       "      <td>67294</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[3268, 370, 21, 1734, 26, 5, 18, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9110410</th>\n",
       "      <td>55162</td>\n",
       "      <td>6659</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[8670, 1188, 8, 42, 65, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834561</th>\n",
       "      <td>82868</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2384, 1953, 2385, 1114, 8, 14, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13164357</th>\n",
       "      <td>134233</td>\n",
       "      <td>23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[63, 4, 26, 27, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating  \\\n",
       "2697298    29690      908     4.0   \n",
       "333591     23485      296     4.5   \n",
       "5156508    96952       11     3.0   \n",
       "9118945    58170     6711     4.5   \n",
       "6295194      559     1183     4.0   \n",
       "11580390  110846     3147     4.5   \n",
       "6591774    67294     2013     1.0   \n",
       "9110410    55162     6659     2.5   \n",
       "3834561    82868     1257     4.0   \n",
       "13164357  134233       23     4.0   \n",
       "\n",
       "                                                  tagvector  \n",
       "2697298   [1042, 174, 1831, 1362, 26, 5, 62, 14, 28, 0, ...  \n",
       "333591    [669, 670, 137, 8, 27, 18, 28, 0, 0, 0, 0, 0, ...  \n",
       "5156508   [36, 37, 21, 4, 8, 18, 14, 0, 0, 0, 0, 0, 0, 0...  \n",
       "9118945   [74, 156, 8729, 7897, 8, 18, 14, 0, 0, 0, 0, 0...  \n",
       "6295194   [2257, 2258, 21, 159, 18, 14, 115, 0, 0, 0, 0,...  \n",
       "11580390  [702, 4665, 21, 2984, 27, 18, 0, 0, 0, 0, 0, 0...  \n",
       "6591774   [3268, 370, 21, 1734, 26, 5, 18, 0, 0, 0, 0, 0...  \n",
       "9110410   [8670, 1188, 8, 42, 65, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3834561   [2384, 1953, 2385, 1114, 8, 14, 0, 0, 0, 0, 0,...  \n",
       "13164357  [63, 4, 26, 27, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class MovieRatingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.dataframe.iloc[idx]['userId']\n",
    "        movie_tags = torch.tensor(self.dataframe.iloc[idx]['tagvector'], dtype=torch.long)\n",
    "        rating = self.dataframe.iloc[idx]['rating']        \n",
    "        return user_id, movie_tags, rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 57218,  42600, 136332, 132179,  32677,  93323,  87079, 117121,  72910,\n",
      "        133823,  81393,  77068,  56727,   4357,  92902,  11491,  55704,  98018,\n",
      "        106922,  58922,  52779, 112940,  72334,  11179, 104669,  17646,  77451,\n",
      "         42020, 108793,  49374,  81161, 103440,  23761, 117459, 132712,  75299,\n",
      "         63237,  28677,  35244,  26923,  86894,  49422, 127719,  22103,  65461,\n",
      "        132736,  67829, 120340, 107862, 121914,  20346,  55056,  92861,  95048,\n",
      "         94536,  40209, 138406,  83090,   6662,  58402,  94957, 105620,  59079,\n",
      "         68699,  68161, 134456,  95526, 103872,  49346,  41831, 100313, 118902,\n",
      "         99555,   5104, 128690,  76929,   8320,  83382,  49514, 114266,  67181,\n",
      "        131721,  15919, 137286,  96691, 131630,  81641,   7531, 119017,  55066,\n",
      "         62751,   5138, 108587,  32441,  24073,  36473, 118256,  47194, 107232,\n",
      "         42733, 137360,  53346, 131695,  43921, 105357,  78083, 122729,  22352,\n",
      "         82202,  35662,  14267,  32048,  38151, 101782,  88015, 137449,  98426,\n",
      "         53590,  25972, 103654,  99225, 120918, 133591,  60203,  50211,  86256,\n",
      "         31393, 111373], dtype=torch.int32)\n",
      "Movie Tags: tensor([[ 424,   20,   21,  ...,    5,   18,    9],\n",
      "        [ 375,  376,    4,  ...,    0,    0,    0],\n",
      "        [1576, 1577,   21,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [2687, 2687, 1568,  ...,    0,    0,    0],\n",
      "        [3143, 5525, 4191,  ...,    0,    0,    0],\n",
      "        [3430, 1363, 1114,  ...,    0,    0,    0]])\n",
      "Ratings: tensor([5.0000, 5.0000, 2.0000, 3.0000, 4.0000, 4.0000, 3.0000, 4.0000, 5.0000,\n",
      "        5.0000, 3.0000, 3.5000, 4.0000, 4.5000, 3.0000, 3.5000, 3.5000, 3.0000,\n",
      "        2.0000, 3.0000, 4.0000, 3.0000, 3.5000, 5.0000, 4.0000, 5.0000, 4.0000,\n",
      "        4.0000, 3.0000, 2.0000, 4.0000, 3.0000, 3.0000, 5.0000, 1.0000, 5.0000,\n",
      "        3.5000, 4.0000, 3.5000, 3.5000, 4.0000, 4.0000, 4.0000, 1.0000, 4.0000,\n",
      "        2.0000, 4.5000, 3.0000, 4.0000, 4.0000, 4.0000, 4.0000, 3.5000, 2.0000,\n",
      "        3.0000, 3.5000, 3.0000, 2.0000, 5.0000, 4.0000, 3.0000, 3.0000, 3.0000,\n",
      "        4.0000, 1.5000, 3.0000, 1.5000, 4.5000, 2.5000, 3.0000, 3.0000, 4.0000,\n",
      "        5.0000, 5.0000, 3.5000, 4.0000, 5.0000, 3.0000, 5.0000, 3.0000, 3.0000,\n",
      "        2.5000, 2.0000, 3.0000, 4.0000, 3.5000, 3.0000, 3.0000, 4.5000, 3.0000,\n",
      "        3.0000, 2.5000, 3.0000, 4.0000, 5.0000, 1.0000, 4.5000, 4.5000, 5.0000,\n",
      "        4.0000, 4.0000, 3.0000, 3.0000, 4.5000, 3.0000, 4.0000, 1.0000, 4.5000,\n",
      "        4.0000, 3.5000, 5.0000, 1.0000, 5.0000, 3.0000, 3.0000, 0.5000, 3.0000,\n",
      "        1.0000, 2.0000, 4.0000, 5.0000, 4.0000, 3.0000, 5.0000, 2.0000, 3.0000,\n",
      "        4.0000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your custom dataset\n",
    "dataset = MovieRatingDataset(user_df[['userId','tagvector','rating']])\n",
    "\n",
    "# Set batch size for DataLoader\n",
    "batch_size = 128\n",
    "\n",
    "# Create a DataLoader using your custom dataset\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader during training\n",
    "for batch in dataloader:\n",
    "    user_ids, movie_tags, ratings = batch\n",
    "    print(\"User IDs:\", user_ids)\n",
    "    print(\"Movie Tags:\", movie_tags)\n",
    "    print(\"Ratings:\", ratings)\n",
    "    break  # only print the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderModel(nn.Module):\n",
    "    def __init__(self, num_users, num_tokens, embedding_dim):\n",
    "        super(RecommenderModel, self).__init__()\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_tokens, embedding_dim)\n",
    "        self.out = nn.Linear(embedding_dim,1)\n",
    "        \n",
    "    def forward(self, user_ids, movie_tags, debug=False):\n",
    "        user_ids = user_ids.to(torch.long)  # Convert to Long data type\n",
    "        movie_tags = movie_tags.to(torch.long)  # Convert to Long data type\n",
    "\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        movie_emb = self.movie_embedding(movie_tags)\n",
    "        interaction = user_emb * movie_emb\n",
    "        x = interaction.mean(dim=1)\n",
    "        output = self.out(x)\n",
    "\n",
    "        if debug:\n",
    "            print('user_emb.shape: ',user_emb.shape)\n",
    "            print('movie_emb.shape: ',movie_emb.shape)\n",
    "            print('interaction.shape: ',interaction.shape)\n",
    "            print('output.shape:',output.shape)\n",
    "\n",
    "            \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecommenderModel(\n",
       "  (user_embedding): Embedding(10, 8)\n",
       "  (movie_embedding): Embedding(20, 8)\n",
       "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RecommenderModel(10, 20, 8)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out = model(torch.randint(1,10,(8,1)), torch.randint(1,20,(8,5)))\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 29464)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.nunique(), len(vectorizer.vocab.word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize your model, optimizer, and loss function\n",
    "num_users = 138493  # Replace with your actual number of users\n",
    "num_tokens = 29464 # Replace with your actual number of tokens\n",
    "dim = 16  # Replace with your desired embedding dimension\n",
    "model = RecommenderModel(num_users, num_tokens, dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Assuming you have a DataLoader named 'dataloader' from the previous example\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Set the number of training epochs\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=10, learning_rate=0.001, device='cpu'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            user_ids, movie_tags, ratings = batch\n",
    "            \n",
    "            user_ids = user_ids.view(-1, 1)\n",
    "            # print('userid shape: ',user_ids.shape)\n",
    "            # print('movie_tags shape: ',movie_tags.shape)\n",
    "            # print('ratings shape: ',ratings.shape)\n",
    "\n",
    "\n",
    "            user_ids = user_ids.to(device)\n",
    "            movie_tags = movie_tags.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(user_ids, movie_tags).squeeze()\n",
    "            # print('pred shape:', outputs.shape)\n",
    "\n",
    "            loss = loss_function(outputs, ratings)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            correct_predictions += torch.sum((outputs - ratings).abs() < 0.5).item()\n",
    "            total_samples += len(ratings)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {average_loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "def inference_model(model, user_ids, movie_tags, device='cpu'):\n",
    "    model.to(device)\n",
    "    user_ids = user_ids.view(-1, 1)\n",
    "    user_ids = user_ids.to(device)\n",
    "    movie_tags = movie_tags.to(device)\n",
    "    outputs = model(user_ids, movie_tags)\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[238], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(model, dataloader, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[236], line 49\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, num_epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m loss_function(outputs, ratings)\n\u001b[1;32m     48\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 49\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     51\u001b[0m correct_predictions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum((outputs \u001b[39m-\u001b[39m ratings)\u001b[39m.\u001b[39mabs() \u001b[39m<\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     52\u001b[0m total_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(ratings)\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.11/site-packages/torch/optim/adam.py:116\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m@_use_grad_for_differentiable\u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, closure\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    110\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Performs a single optimization step.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m            and returns the loss.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cuda_graph_capture_health_check()\n\u001b[1;32m    118\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.11/site-packages/torch/optim/optimizer.py:230\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_graph_capture_health_check\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mhas_cuda \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 230\u001b[0m         capturing \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mis_current_stream_capturing()\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m capturing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(group[\u001b[39m'\u001b[39m\u001b[39mcapturable\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups):\n\u001b[1;32m    233\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    234\u001b[0m                                \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    235\u001b[0m                                \u001b[39m\"\u001b[39m\u001b[39m but param_groups\u001b[39m\u001b[39m'\u001b[39m\u001b[39m capturable is False.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deep/lib/python3.11/site-packages/torch/cuda/graphs.py:25\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_current_stream_capturing\u001b[39m():\n\u001b[1;32m     20\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m    Returns True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[39m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m _cuda_isCurrentStreamCapturing()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, num_epochs=1, learning_rate=0.01, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
