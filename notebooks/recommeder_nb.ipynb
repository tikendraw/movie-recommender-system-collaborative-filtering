{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os, time, random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Callable, List\n",
    "from functools import cache\n",
    "import re\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = Path('.').absolute()\n",
    "data_dir=cur_dir.parent/ 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/tag.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/movie.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/link.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/rating.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/movies.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/genome_tags.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/genome_scores.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Movie df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv(data_dir/'movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27278 entries, 0 to 27277\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  27278 non-null  int64 \n",
      " 1   title    27278 non-null  object\n",
      " 2   genres   27278 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 639.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId    0\n",
       "title      0\n",
       "genres     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.isna().sum() # no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.duplicated().sum() #no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27262"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aladdin (1992)', 'Johnny Express (2014)', 'Chaos (2005)', 'Hamlet (2000)', '20,000 Leagues Under the Sea (1997)', 'Darling (2007)', 'Casanova (2005)', 'Paradise (2013)', 'Beneath (2013)', 'Girl, The (2012)', 'Clear History (2013)', 'Emma (1996)', 'Offside (2006)', 'Blackout (2007)', 'Men with Guns (1997)', 'War of the Worlds (2005)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the value counts for each movie title\n",
    "title_value_counts = movie_df['title'].value_counts()\n",
    "\n",
    "# Filter titles that appear more than once\n",
    "duplicate_titles = title_value_counts[title_value_counts > 1].index.tolist()\n",
    "\n",
    "print(duplicate_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some movies have multiple entries with different `movieid` , but it doesn't affect much "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so in genres column there seems to have no spaces bw genres, lets see want unique genres as there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = movie_df.genres.apply(lambda x : ' '.join(str(x).split('|'))).values.tolist() # split from |\n",
    "all_genres = ' '.join(set(all_genres)).split() # join all strings and break them into words\n",
    "all_genres = set(all_genres)  # make a set to find unique ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sci-Fi', 'IMAX', 'Action', 'War', 'Horror', 'Film-Noir', 'Children', 'listed)', 'Comedy', 'Adventure', '(no', 'Animation', 'Fantasy', 'Musical', 'Documentary', 'Mystery', 'Drama', 'Western', 'Crime', 'Thriller', 'Romance', 'genres'} 22\n"
     ]
    }
   ],
   "source": [
    "print(all_genres, len(all_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 20 genres and 1 for movies with no genre (which is (no listed)) which is broken as '(no' and 'listed)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a tag columns that contains all information about movie in a sentence\n",
    "movie_df['tags'] = movie_df['title'] + ' ' + movie_df['genres'].apply(lambda x: ' '.join(str(x).split('|')))\n",
    "movie_df['tags'] = movie_df['tags'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_df['Title'] = movie_df.title.apply(lambda x : str(x).split('(')[0])\n",
    "# movie_df['Year'] = movie_df.title.apply(lambda x : (str(x).split('(')[-1]).strip(')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11585</th>\n",
       "      <td>50610</td>\n",
       "      <td>Beer League (2006)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>beer league (2006) comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>32168</td>\n",
       "      <td>Or (a.k.a. My Treasure) (2004)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>or (a.k.a. my treasure) (2004) drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18703</th>\n",
       "      <td>93139</td>\n",
       "      <td>Mega Shark vs. Crocosaurus (2010)</td>\n",
       "      <td>Action|Adventure|Horror</td>\n",
       "      <td>mega shark vs. crocosaurus (2010) action adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26115</th>\n",
       "      <td>125571</td>\n",
       "      <td>The Court-Martial of Jackie Robinson</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>the court-martial of jackie robinson (no genre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10193</th>\n",
       "      <td>33901</td>\n",
       "      <td>Satan's Little Helper (2004)</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "      <td>satan's little helper (2004) comedy horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>60524</td>\n",
       "      <td>August (2008)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>august (2008) drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20286</th>\n",
       "      <td>99741</td>\n",
       "      <td>Company You Keep, The (2012)</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>company you keep, the (2012) thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8278</th>\n",
       "      <td>8961</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "      <td>Action|Adventure|Animation|Children|Comedy</td>\n",
       "      <td>incredibles, the (2004) action adventure anima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15085</th>\n",
       "      <td>76709</td>\n",
       "      <td>Spider-Man: The Ultimate Villain Showdown (2002)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>spider-man: the ultimate villain showdown (200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22859</th>\n",
       "      <td>109290</td>\n",
       "      <td>The African (1983)</td>\n",
       "      <td>Adventure|Comedy</td>\n",
       "      <td>the african (1983) adventure comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>55485</td>\n",
       "      <td>Fugitive Pieces (2007)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>fugitive pieces (2007) drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1749</td>\n",
       "      <td>Leading Man, The (1996)</td>\n",
       "      <td>Romance</td>\n",
       "      <td>leading man, the (1996) romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>64900</td>\n",
       "      <td>Chinese Ghost Story II, A (Sien nui yau wan II...</td>\n",
       "      <td>Action|Adventure|Fantasy|Horror|Romance</td>\n",
       "      <td>chinese ghost story ii, a (sien nui yau wan ii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>2392</td>\n",
       "      <td>Jack Frost (1998)</td>\n",
       "      <td>Children|Comedy|Drama</td>\n",
       "      <td>jack frost (1998) children comedy drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17977</th>\n",
       "      <td>90201</td>\n",
       "      <td>Grand Dukes, The (Les grands ducs) (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>grand dukes, the (les grands ducs) (1996) comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26303</th>\n",
       "      <td>126286</td>\n",
       "      <td>Double Or Nothing (1937)</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>double or nothing (1937) (no genres listed)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16349</th>\n",
       "      <td>82499</td>\n",
       "      <td>How Do You Know (2010)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>how do you know (2010) comedy drama romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>2622</td>\n",
       "      <td>William Shakespeare's A Midsummer Night's Drea...</td>\n",
       "      <td>Comedy|Fantasy</td>\n",
       "      <td>william shakespeare's a midsummer night's drea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23084</th>\n",
       "      <td>110097</td>\n",
       "      <td>From Dad to Son (2012)</td>\n",
       "      <td>Animation|Drama</td>\n",
       "      <td>from dad to son (2012) animation drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>7079</td>\n",
       "      <td>Hunchback of Notre Dame, The (1939)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>hunchback of notre dame, the (1939) drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9471</th>\n",
       "      <td>27765</td>\n",
       "      <td>Trauma (2004)</td>\n",
       "      <td>Drama|Mystery|Thriller</td>\n",
       "      <td>trauma (2004) drama mystery thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13116</th>\n",
       "      <td>63229</td>\n",
       "      <td>Feiern (2006)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>feiern (2006) documentary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                              title  \\\n",
       "11585    50610                                 Beer League (2006)   \n",
       "9849     32168                     Or (a.k.a. My Treasure) (2004)   \n",
       "18703    93139                  Mega Shark vs. Crocosaurus (2010)   \n",
       "26115   125571               The Court-Martial of Jackie Robinson   \n",
       "10193    33901                       Satan's Little Helper (2004)   \n",
       "12833    60524                                      August (2008)   \n",
       "20286    99741                       Company You Keep, The (2012)   \n",
       "8278      8961                            Incredibles, The (2004)   \n",
       "15085    76709   Spider-Man: The Ultimate Villain Showdown (2002)   \n",
       "22859   109290                                 The African (1983)   \n",
       "12177    55485                             Fugitive Pieces (2007)   \n",
       "1685      1749                            Leading Man, The (1996)   \n",
       "13249    64900  Chinese Ghost Story II, A (Sien nui yau wan II...   \n",
       "2307      2392                                  Jack Frost (1998)   \n",
       "17977    90201          Grand Dukes, The (Les grands ducs) (1996)   \n",
       "26303   126286                           Double Or Nothing (1937)   \n",
       "16349    82499                             How Do You Know (2010)   \n",
       "2537      2622  William Shakespeare's A Midsummer Night's Drea...   \n",
       "23084   110097                             From Dad to Son (2012)   \n",
       "6967      7079                Hunchback of Notre Dame, The (1939)   \n",
       "9471     27765                                      Trauma (2004)   \n",
       "13116    63229                                      Feiern (2006)   \n",
       "\n",
       "                                           genres  \\\n",
       "11585                                      Comedy   \n",
       "9849                                        Drama   \n",
       "18703                     Action|Adventure|Horror   \n",
       "26115                          (no genres listed)   \n",
       "10193                               Comedy|Horror   \n",
       "12833                                       Drama   \n",
       "20286                                    Thriller   \n",
       "8278   Action|Adventure|Animation|Children|Comedy   \n",
       "15085                                   Animation   \n",
       "22859                            Adventure|Comedy   \n",
       "12177                                       Drama   \n",
       "1685                                      Romance   \n",
       "13249     Action|Adventure|Fantasy|Horror|Romance   \n",
       "2307                        Children|Comedy|Drama   \n",
       "17977                                      Comedy   \n",
       "26303                          (no genres listed)   \n",
       "16349                        Comedy|Drama|Romance   \n",
       "2537                               Comedy|Fantasy   \n",
       "23084                             Animation|Drama   \n",
       "6967                                        Drama   \n",
       "9471                       Drama|Mystery|Thriller   \n",
       "13116                                 Documentary   \n",
       "\n",
       "                                                    tags  \n",
       "11585                          beer league (2006) comedy  \n",
       "9849                or (a.k.a. my treasure) (2004) drama  \n",
       "18703  mega shark vs. crocosaurus (2010) action adven...  \n",
       "26115  the court-martial of jackie robinson (no genre...  \n",
       "10193         satan's little helper (2004) comedy horror  \n",
       "12833                                august (2008) drama  \n",
       "20286              company you keep, the (2012) thriller  \n",
       "8278   incredibles, the (2004) action adventure anima...  \n",
       "15085  spider-man: the ultimate villain showdown (200...  \n",
       "22859                the african (1983) adventure comedy  \n",
       "12177                       fugitive pieces (2007) drama  \n",
       "1685                     leading man, the (1996) romance  \n",
       "13249  chinese ghost story ii, a (sien nui yau wan ii...  \n",
       "2307             jack frost (1998) children comedy drama  \n",
       "17977   grand dukes, the (les grands ducs) (1996) comedy  \n",
       "26303        double or nothing (1937) (no genres listed)  \n",
       "16349        how do you know (2010) comedy drama romance  \n",
       "2537   william shakespeare's a midsummer night's drea...  \n",
       "23084             from dad to son (2012) animation drama  \n",
       "6967           hunchback of notre dame, the (1939) drama  \n",
       "9471                trauma (2004) drama mystery thriller  \n",
       "13116                          feiern (2006) documentary  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.sample(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploraing User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(data_dir/'rating.csv', usecols=['userId','movieId','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 1, 138493)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this columns are using too much precision for very low values, lowering the datatype precision\n",
    "user_df['movieId'] = user_df['movieId'].astype('int32')\n",
    "user_df['userId'] = user_df['userId'].astype('int32')\n",
    "user_df['rating'] = user_df['rating'].astype('float32')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 1, 138493)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000263, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape #(20000263,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   userId   int32  \n",
      " 1   movieId  int32  \n",
      " 2   rating   float32\n",
      "dtypes: float32(1), int32(2)\n",
      "memory usage: 228.9 MB\n"
     ]
    }
   ],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        2     3.5\n",
       "1       1       29     3.5\n",
       "2       1       32     3.5\n",
       "3       1       47     3.5\n",
       "4       1       50     3.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x: str) -> str:\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)  # Remove punctuation\n",
    "    x = x.lower()  # Convert to lowercase\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helo 44 sir'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'helo#$#@$#%$@%@#$ 44 sir'\n",
    "clean_text(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, special_tokens: List[str]):\n",
    "        self.word_to_idx = {}\n",
    "        self.idx_to_word = {}\n",
    "        self.counter = Counter()\n",
    "        \n",
    "        self.UNK_TOKEN = '<UNK>'\n",
    "        self.UNK = 1\n",
    "        self.PAD_TOKEN = '<PAD>'\n",
    "        self.PAD = 0\n",
    "        \n",
    "        self.word_to_idx[self.UNK_TOKEN] = self.UNK\n",
    "        self.idx_to_word[self.UNK] = self.UNK_TOKEN\n",
    "\n",
    "        self.word_to_idx[self.PAD_TOKEN] = self.PAD\n",
    "        self.idx_to_word[self.PAD] = self.PAD_TOKEN\n",
    "\n",
    "        self.vocab_size = 2\n",
    "        for idx, token in enumerate(special_tokens, start=2):\n",
    "            self.word_to_idx[token] = idx\n",
    "            self.idx_to_word[idx] = token\n",
    "            self.vocab_size += 1\n",
    "\n",
    "    def build_vocab(self, tokenized_data, max_tokens, min_freq):\n",
    "        self.counter = Counter()\n",
    "        for words in tokenized_data:\n",
    "            self.counter.update(words)\n",
    "\n",
    "        if max_tokens is not None:\n",
    "            sorted_tokens = [word for word, _ in self.counter.most_common()]\n",
    "            for word in sorted_tokens:\n",
    "                if word not in self.word_to_idx:\n",
    "                    self.add_word_to_vocab(word)\n",
    "\n",
    "                if self.vocab_size == max_tokens - 1:\n",
    "                    break\n",
    "        else:\n",
    "            for word, freq in self.counter.items():\n",
    "                if freq >= min_freq and word not in self.word_to_idx:\n",
    "                    self.add_word_to_vocab(word)\n",
    "\n",
    "    def add_word_to_vocab(self, word):\n",
    "        self.word_to_idx[word] = self.vocab_size\n",
    "        self.idx_to_word[self.vocab_size] = word\n",
    "        self.vocab_size += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class IntegerVectorizer:\n",
    "    def __init__(self, \n",
    "                 tokenizer: Callable[[str], List[str]] = None,\n",
    "                 preprocessing_func: Callable[[str], str] = None,\n",
    "                 max_tokens=None,\n",
    "                 min_freq=1,\n",
    "                 special_tokens: List[str] = None,\n",
    "                 max_seq_length=None,\n",
    "                 pad_to_max=False):\n",
    "        \n",
    "        self.min_freq = min_freq\n",
    "        self.max_tokens = max_tokens\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        self.reserved_tokens = ['<UNK>', '<PAD>']\n",
    "        self.special_tokens = [token for token in special_tokens if token not in self.reserved_tokens] if special_tokens else []\n",
    "        self.pad_to_max = pad_to_max  # Store the argument\n",
    "\n",
    "        self.vocab = Vocabulary(self.special_tokens)\n",
    "        self.tokenized_data = []\n",
    "\n",
    "    def adapt(self, data):\n",
    "        self.tokenized_data = self.tokenize_data_generator(data)\n",
    "        self.vocab.build_vocab(self.tokenized_data, self.max_tokens, self.min_freq)\n",
    "        print('Vocab size:', len(self.vocab))\n",
    "\n",
    "    def __call__(self, data, reverse=False):\n",
    "        if reverse:\n",
    "            return self.reverse_transform(data)\n",
    "        else:\n",
    "            return self.transform(data)\n",
    "\n",
    "    def preprocess_sentence(self, sentence):\n",
    "        if self.preprocessing_func:\n",
    "            words = sentence.split()\n",
    "            preprocessed_words = [self.preprocessing_func(word) if word not in self.special_tokens else word for word in words]\n",
    "            return \" \".join(preprocessed_words)\n",
    "        return sentence\n",
    "\n",
    "    def tokenize_data_generator(self, data):\n",
    "        for sentence in data:\n",
    "            sentence = self.preprocess_sentence(sentence)\n",
    "            words = self.tokenizer(sentence) if self.tokenizer else sentence.split()\n",
    "            yield words\n",
    "\n",
    "    def transform(self, data):\n",
    "        self.tokenized_data = self.tokenize_data_generator(data)\n",
    "        vectorized_data = []\n",
    "        for sentence in self.tokenized_data:\n",
    "            vectorized_sentence = [self.vocab.word_to_idx.get(word, self.vocab.UNK) for word in sentence]\n",
    "            vectorized_sentence = self.adjust_sequence_length(vectorized_sentence)\n",
    "            vectorized_data.append(vectorized_sentence)\n",
    "        return vectorized_data\n",
    "\n",
    "    def adjust_sequence_length(self, sequence):\n",
    "        if self.max_seq_length is not None:\n",
    "            if len(sequence) < self.max_seq_length:\n",
    "                if self.pad_to_max:  # Check the new argument\n",
    "                    sequence += [self.vocab.PAD] * (self.max_seq_length - len(sequence))\n",
    "            elif len(sequence) > self.max_seq_length:\n",
    "                sequence = sequence[:self.max_seq_length]\n",
    "        return sequence\n",
    "\n",
    "\n",
    "    def reverse_transform(self, vectorized_data: List[List[int]]) -> List[str]:\n",
    "        original_data = []\n",
    "        for vector in vectorized_data:\n",
    "            sentence = [self.vocab.idx_to_word[idx] for idx in vector if idx != self.vocab.PAD]\n",
    "            original_data.append(\" \".join(sentence))\n",
    "        return original_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 14\n",
      "Original data: ['This is a sample sentence (23). <UNK>', '<START> Another example sentence. <END>', '<START> This is another sentence. <END>', '3 3 3 3 3 3 ']\n",
      "Vectorized data: [[2, 3, 4, 5, 6, 7, 8], [9, 10, 11, 6, 12], [9, 2, 3, 10, 6, 12], [13, 13, 13, 13, 13, 13]]\n",
      "reverse vec:  ['this is a sample sentence 23 unk', 'start another example sentence end', 'start this is another sentence end', '3 3 3 3 3 3']\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    \"This is a sample sentence (23). <UNK>\",\n",
    "    \"<START> Another example sentence. <END>\",\n",
    "    \"<START> This is another sentence. <END>\",\n",
    "    '3 3 3 3 3 3 '\n",
    "]\n",
    "min_freq = 2\n",
    "max_tokens = None\n",
    "special_tokens = ['<START>', '<END>', '<UNK>','<PAD>']\n",
    "\n",
    "\n",
    "vectorizer = IntegerVectorizer(preprocessing_func=clean_text, max_seq_length=10, pad_to_max=False)\n",
    "vectorizer.adapt(data)\n",
    "a = vectorizer(data)\n",
    "b = vectorizer.reverse_transform(a)\n",
    "\n",
    "\n",
    "print(\"Original data:\", data)\n",
    "print(\"Vectorized data:\", a)\n",
    "print('reverse vec: ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       user_df: 228.9 MiB\n",
      "                      movie_df:  7.0 MiB\n",
      "            title_value_counts:  2.5 MiB\n",
      "                           _15:  5.9 KiB\n",
      "                           _ii:  3.0 KiB\n",
      "                          _i26:  3.0 KiB\n",
      "                    all_genres:  2.2 KiB\n",
      "                       Counter:  1.6 KiB\n",
      "                    Vocabulary:  1.6 KiB\n",
      "             IntegerVectorizer:  1.6 KiB\n"
     ]
    }
   ],
   "source": [
    "def sizeof_fmt(num, suffix=\"B\"):\n",
    "    \n",
    "    \"\"\"by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified\"\"\"\n",
    "    for unit in [\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\", \"Pi\", \"Ei\", \"Zi\"]:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, \"Yi\", suffix)\n",
    "    \n",
    "\n",
    "for name, size in sorted(\n",
    "    ((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "    key=lambda x: -x[1],\n",
    ")[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class MovieRatingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id = self.dataframe.iloc[idx]['userId']\n",
    "        movie_tags = torch.tensor(self.dataframe.iloc[idx]['tagvector'], dtype=torch.long)\n",
    "        # movie_tags = self.dataframe.iloc[idx]['movieId']\n",
    "        rating = self.dataframe.iloc[idx]['rating']        \n",
    "        return user_id, movie_tags, rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderModel(nn.Module):\n",
    "    def __init__(self, num_users, num_tokens, embedding_dim):\n",
    "        super(RecommenderModel, self).__init__()\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users+1, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_tokens+1, embedding_dim)\n",
    "        self.out = nn.Linear(embedding_dim,1)\n",
    "        \n",
    "    def forward(self, user_ids, movie_tags, debug=False):\n",
    "        user_ids = user_ids.to(torch.long)  # Convert to Long data type\n",
    "        movie_tags = movie_tags.to(torch.long)  # Convert to Long data type\n",
    "\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        movie_emb = self.movie_embedding(movie_tags)\n",
    "        interaction = user_emb * movie_emb\n",
    "        x = interaction.mean(dim=1)\n",
    "        output = self.out(x)\n",
    "\n",
    "        if debug:\n",
    "            print('user_emb.shape: ',user_emb.shape)\n",
    "            print('movie_emb.shape: ',movie_emb.shape)\n",
    "            print('interaction.shape: ',interaction.shape)\n",
    "            print('output.shape:',output.shape)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecommenderModel(\n",
       "  (user_embedding): Embedding(11, 8)\n",
       "  (movie_embedding): Embedding(21, 8)\n",
       "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RecommenderModel(10, 20, 8)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out = model(torch.randint(1,10,(8,1)), torch.randint(1,20,(8,1)))\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 22693\n"
     ]
    }
   ],
   "source": [
    "#adapt to data\n",
    "vectorizer = IntegerVectorizer(preprocessing_func=clean_text,max_seq_length=10, pad_to_max=True)\n",
    "vectorizer.adapt(movie_df['tags'].tolist()) #22693\n",
    "\n",
    "# vectorize the data\n",
    "movie_df['tagvector'] = movie_df['tags'].apply(lambda x : vectorizer.transform([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge movie_df to user_df\n",
    "user_df = user_df.merge(movie_df[['movieId','tagvector']], on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.max(), user_df.userId.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000236, 4) (20001, 4)\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "train_df, test_df = train_test_split(user_df[['userId','tagvector','rating', 'movieId']], train_size=.9, test_size=.001, random_state=2)\n",
    "print(train_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([118432,  41859,  81172,  46179,  12887,  39382,  26227,  24269, 129775,\n",
      "          3397, 137993,  51370, 121884, 134225,  52948,  26612, 112988,  43545,\n",
      "         32340,  68625,  74122,  26425,  81984, 136204, 114713, 102242,  32865,\n",
      "         19353,   5074, 135724,   4040,   7032], dtype=torch.int32)\n",
      "Movie Tags: tensor([[  988,   989,   566,    21,   134,    26,     7,    14,     0,     0],\n",
      "        [ 1745,    21,  1700,  1050,  1173,     8,     0,     0,     0,     0],\n",
      "        [  724,   725,   726,   727,   421,    18,     0,     0,     0,     0],\n",
      "        [  314,   569,   570,  1152,    21,  2091,  2092,  2053,  1320,    26],\n",
      "        [ 5124,   667,  1722,    18,   126,    14,     0,     0,     0,     0],\n",
      "        [  129,   341,   421,    26,    18,     0,     0,     0,     0,     0],\n",
      "        [  991,   171,  1702,  1288,    26,     5,    62,    14,    28,     0],\n",
      "        [ 1604,    13,  1464,     8,    18,     0,     0,     0,     0,     0],\n",
      "        [  777,   281,  1073,    21,   421,     6,     7,     9,   126,     0],\n",
      "        [ 1710,  1262,  1711,     8,    18,    14,     0,     0,     0,     0],\n",
      "        [ 5216,  1305,    21,  1173,    26,     8,     0,     0,     0,     0],\n",
      "        [ 1720,  1721,  1709,    18,    62,     0,     0,     0,     0,     0],\n",
      "        [  123,    91,   124,     4,    62,    28,     0,     0,     0,     0],\n",
      "        [ 1381,   321,   261,  1664,    18,    14,     0,     0,     0,     0],\n",
      "        [  405,  1907,    21,   581,  1908,  1859,     7,     8,     9,   126],\n",
      "        [  300,   575,   134,    18,     0,     0,     0,     0,     0,     0],\n",
      "        [  218,  1449,    21,  7673,     8,     0,     0,     0,     0,     0],\n",
      "        [ 5830,    21,  5481,    18,     0,     0,     0,     0,     0,     0],\n",
      "        [  630,    21,  2133,    18,     0,     0,     0,     0,     0,     0],\n",
      "        [ 7331, 13020, 15428,    26,     9,    28,    95,     0,     0,     0],\n",
      "        [ 3101,   451,    83,    58,  1687,    27,    18,   395,    28,     0],\n",
      "        [  919,    21,   421,    28,     0,     0,     0,     0,     0,     0],\n",
      "        [  130,   131,    21,     4,    27,    62,    28,     0,     0,     0],\n",
      "        [ 2182,  1921,    21,  2106,    27,    28,   112,     0,     0,     0],\n",
      "        [  218,  2922,    21,  6654,    26,     5,    18,   112,     0,     0],\n",
      "        [  127,  1691,    21,  4792,    83,  1750,     8,   126,    14,     0],\n",
      "        [  996,    21,   421,    18,    14,     0,     0,     0,     0,     0],\n",
      "        [ 1695,  1150,  1696,    62,    28,     0,     0,     0,     0,     0],\n",
      "        [  402,  1572,   734,    21,   156,     8,     0,     0,     0,     0],\n",
      "        [ 3425,  3426,    21,  1518,    26,     5,    18,    28,     0,     0],\n",
      "        [ 2792,    20,  2310,    21,  1148,    18,     0,     0,     0,     0],\n",
      "        [ 5393,  1140,    18,    65,    28,     0,     0,     0,     0,     0]])\n",
      "Ratings: tensor([3.0000, 2.0000, 2.0000, 5.0000, 4.5000, 3.5000, 4.0000, 3.0000, 3.5000,\n",
      "        3.5000, 3.5000, 4.0000, 4.5000, 3.0000, 0.5000, 5.0000, 3.0000, 2.0000,\n",
      "        3.0000, 4.0000, 4.5000, 3.0000, 4.0000, 3.0000, 4.5000, 3.5000, 3.0000,\n",
      "        4.5000, 3.0000, 2.0000, 5.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Set batch size for DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "# train\n",
    "train_dataset = MovieRatingDataset(train_df)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test\n",
    "test_dataset = MovieRatingDataset(test_df)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader during training\n",
    "for batch in train_dataloader:\n",
    "    user_ids, movie_tags, ratings = batch\n",
    "    print(\"User IDs:\", user_ids)\n",
    "    print(\"Movie Tags:\", movie_tags)\n",
    "    print(\"Ratings:\", ratings)\n",
    "    break  # only print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 27278, 22693)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.nunique(),movie_df.movieId.nunique(), len(vectorizer.vocab.word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max userid value:  138493\n",
      "unique userid:  138493\n"
     ]
    }
   ],
   "source": [
    "print('max userid value: ',user_df.userId.max())\n",
    "print('unique userid: ',user_df.userId.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max vocab value:  22692\n",
      "vocab size:  22693\n"
     ]
    }
   ],
   "source": [
    "print('max vocab value: ',max(vectorizer.vocab.word_to_idx.values()))\n",
    "print('vocab size: ',len(vectorizer.vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model, optimizer, and loss function\n",
    "num_users = user_df.userId.nunique()  # actual number of users\n",
    "num_tokens = len(vectorizer.vocab) # actual number of tokens\n",
    "dim = 8  \n",
    "model = RecommenderModel(num_users, num_tokens, dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1  # Set the number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_function, num_epochs=10, device='cpu', data_percent=1.0, steps_per_epoch=None):\n",
    "    model.to(device)\n",
    "    print(f'{model.__class__.__name__} Running on : {device}')\n",
    "\n",
    "    data_size = int(data_percent * len(dataloader))\n",
    "    dataloader = iter(dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        epoch_progress = tqdm(range(data_size), desc=f\"Epoch [{epoch+1:2}/{num_epochs:2}]\")\n",
    "        \n",
    "        if steps_per_epoch is not None:\n",
    "            epoch_progress = tqdm(range(steps_per_epoch), desc=f\"Epoch [{epoch+1:2}/{num_epochs:2}]\")\n",
    "\n",
    "        for _ in epoch_progress:\n",
    "            try:\n",
    "                batch = next(dataloader)\n",
    "            except StopIteration:\n",
    "                dataloader = iter(dataloader)\n",
    "                batch = next(dataloader)\n",
    "\n",
    "            user_ids, movie_tags, ratings = batch\n",
    "            \n",
    "            user_ids = user_ids.view(-1, 1)\n",
    "\n",
    "            user_ids = user_ids.to(device)\n",
    "            movie_tags = movie_tags.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(user_ids, movie_tags).squeeze()\n",
    "\n",
    "            loss = loss_function(outputs, ratings)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            correct_predictions += torch.sum((outputs - ratings).abs() < 0.5).item()\n",
    "            total_samples += len(ratings)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            formatted_loss = f\"{loss.item():.8f}\"\n",
    "            formatted_accuracy = f\"{correct_predictions / total_samples:.8f}\"\n",
    "\n",
    "            epoch_progress.set_postfix({\"Loss\": formatted_loss, \"Accuracy\": formatted_accuracy})\n",
    "            epoch_progress.update()\n",
    "\n",
    "            if steps_per_epoch is not None and _ + 1 >= steps_per_epoch:\n",
    "                break\n",
    "\n",
    "        # epoch_progress.close()\n",
    "\n",
    "        average_loss = total_loss / min(data_size, steps_per_epoch) if steps_per_epoch is not None else total_loss / data_size\n",
    "        accuracy = correct_predictions / total_samples\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1:2}/{num_epochs:2}] - Average Loss: {average_loss:.8f} - Average Accuracy: {accuracy:.8f}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, dataloader, device='cpu'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)\n",
    "    \n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            user_ids, movie_tags, ratings = batch\n",
    "            \n",
    "            user_ids = user_ids.view(-1, 1)\n",
    "\n",
    "            user_ids = user_ids.to(device)\n",
    "            movie_tags = movie_tags.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            outputs = model(user_ids, movie_tags).squeeze()\n",
    "\n",
    "            labels.extend(ratings.cpu().numpy())\n",
    "            \n",
    "            if len(outputs.shape) == 0:\n",
    "                predictions.append(outputs.item())\n",
    "            else:\n",
    "                predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    print('Mean Squared Error: ',mean_squared_error(labels, predictions))\n",
    "    print('Mean Absolute Error: ',mean_absolute_error(labels, predictions))\n",
    "    return labels, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model, train_dataloader,  optimizer, loss_function, num_epochs=1, device=device, data_percent=0.03, steps_per_epoch=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t/aproject/movie-recommender-system-collaborative-filtering/models\n"
     ]
    }
   ],
   "source": [
    "# SAVe the model\n",
    "model_path = cur_dir.parent/'models'\n",
    "# print(model_path)\n",
    "torch.save(model.state_dict(), model_path/'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, predictions = inference(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:  0.8249118893361443\n",
      "mean_absolute_error:  0.695049490650191\n"
     ]
    }
   ],
   "source": [
    "print('mean_squared_error: ',mean_squared_error(labels, predictions))\n",
    "print('mean_absolute_error: ',mean_absolute_error(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
