{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory:  /home/t/aproject/movie-recommender-system-collaborative-filtering/notebooks\n"
     ]
    }
   ],
   "source": [
    "cur_dir = Path('.').absolute()\n",
    "data_dir=cur_dir.parent/ 'data'\n",
    "\n",
    "print('current directory: ',cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/tag.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/movie.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/link.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/rating.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/new_movie_df.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/movies.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/plot_embedding.csv'),\n",
       " PosixPath('/home/t/aproject/movie-recommender-system-collaborative-filtering/data/new_user_df.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Movie df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv(data_dir/'movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_name(idx, df):\n",
    "    try:\n",
    "        return df[df.movieId==idx].title.values[0]\n",
    "    except IndexError as e:\n",
    "        print(\"IndexError:\", idx)\n",
    "\n",
    "def get_movie_id(movie_name, df):\n",
    "    try:\n",
    "        return df[df.title==movie_name].movieId.values[0]\n",
    "    except IndexError as e:\n",
    "        print(\"Movie not found in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27278 entries, 0 to 27277\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  27278 non-null  int64 \n",
      " 1   title    27278 non-null  object\n",
      " 2   genres   27278 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 639.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId    0\n",
       "title      0\n",
       "genres     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.isna().sum() # no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.duplicated().sum() #no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aladdin (1992)', 'Johnny Express (2014)', 'Chaos (2005)', 'Hamlet (2000)', '20,000 Leagues Under the Sea (1997)', 'Darling (2007)', 'Casanova (2005)', 'Paradise (2013)', 'Beneath (2013)', 'Girl, The (2012)', 'Clear History (2013)', 'Emma (1996)', 'Offside (2006)', 'Blackout (2007)', 'Men with Guns (1997)', 'War of the Worlds (2005)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the value counts for each movie title\n",
    "title_value_counts = movie_df['title'].value_counts()\n",
    "\n",
    "# Filter titles that appear more than once\n",
    "duplicate_titles = title_value_counts[title_value_counts > 1].index.tolist()\n",
    "\n",
    "print(duplicate_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some movies have multiple entries with different `movieid` , but it doesn't affect much "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so in genres column there seems to have no spaces bw genres, lets see want unique genres as there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = movie_df.genres.apply(lambda x : ' '.join(str(x).split('|'))).values.tolist() # split from |\n",
    "all_genres = ' '.join(set(all_genres)).split() # join all strings and break them into words\n",
    "all_genres = set(all_genres)  # make a set to find unique ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Romance', 'Comedy', 'Drama', 'Western', 'Fantasy', 'genres', 'Mystery', 'Documentary', 'listed)', 'Film-Noir', 'Adventure', 'IMAX', 'War', 'Action', 'Children', 'Horror', 'Musical', 'Crime', '(no', 'Thriller', 'Animation', 'Sci-Fi'} 22\n"
     ]
    }
   ],
   "source": [
    "print(all_genres, len(all_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 20 genres and 1 for movies with no genre (which is (no listed)) which is broken as '(no' and 'listed)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are alot of movies that only has 1,2 reviews , so now we will only consider mmovies which has more than 100 review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploraing User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(data_dir/'rating.csv', usecols=['userId','movieId','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this columns are using too much precision for very low values, lowering the datatype precision\n",
    "user_df['movieId'] = user_df['movieId'].astype('int32') # dont lower too much as it changes the numbers to accomodate to the range\n",
    "user_df['userId'] = user_df['userId'].astype('int32')\n",
    "user_df['rating'] = user_df['rating'].astype('float32')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 1, 138493)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000263, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape #(20000263,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000263 entries, 0 to 20000262\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   userId   int32  \n",
      " 1   movieId  int32  \n",
      " 2   rating   float32\n",
      "dtypes: float32(1), int32(2)\n",
      "memory usage: 228.9 MB\n"
     ]
    }
   ],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        2     3.5\n",
       "1       1       29     3.5\n",
       "2       1       32     3.5\n",
       "3       1       47     3.5\n",
       "4       1       50     3.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding out reviews per movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "296       67310\n",
       "356       66172\n",
       "318       63366\n",
       "593       63299\n",
       "480       59715\n",
       "          ...  \n",
       "125545        1\n",
       "78873         1\n",
       "112907        1\n",
       "112909        1\n",
       "110510        1\n",
       "Name: count, Length: 26744, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_vote_count = user_df.movieId.value_counts()\n",
    "movie_vote_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most voted movies\n",
      "Pulp Fiction (1994)                 : 67310\n",
      "Forrest Gump (1994)                 : 66172\n",
      "Shawshank Redemption, The (1994)    : 63366\n",
      "Silence of the Lambs, The (1991)    : 63299\n",
      "Jurassic Park (1993)                : 59715\n",
      "Star Wars: Episode IV - A New Hope (1977) : 54502\n",
      "Braveheart (1995)                   : 53769\n",
      "Terminator 2: Judgment Day (1991)   : 52244\n",
      "Matrix, The (1999)                  : 51334\n",
      "Schindler's List (1993)             : 50054\n",
      "Toy Story (1995)                    : 49695\n",
      "Fugitive, The (1993)                : 49581\n",
      "Apollo 13 (1995)                    : 47777\n",
      "Independence Day (a.k.a. ID4) (1996) : 47048\n",
      "Usual Suspects, The (1995)          : 47006\n",
      "Star Wars: Episode VI - Return of the Jedi (1983) : 46839\n",
      "Batman (1989)                       : 46054\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) : 45313\n",
      "American Beauty (1999)              : 44987\n",
      "Twelve Monkeys (a.k.a. 12 Monkeys) (1995) : 44980\n"
     ]
    }
   ],
   "source": [
    "print('Most voted movies')\n",
    "i=20\n",
    "for idx, count in zip(movie_vote_count.index ,movie_vote_count.to_list()):\n",
    "    print(f\"{get_movie_name(idx, movie_df):35} : {count}\")\n",
    "    i -= 1\n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df_rating_filter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   296,    356,    318,    593,    480,    260,    110,    589,   2571,\n",
       "          527,\n",
       "       ...\n",
       "       112911,   8201,  30867,    687,  71878,   4208,  59915,   5256,  51127,\n",
       "        26746],\n",
       "      dtype='int32', name='movieId', length=8546)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_movieIds = movie_vote_count[movie_vote_count>=movie_df_rating_filter].index\n",
    "popular_movieIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19706281, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_df = user_df[user_df['movieId'].isin(popular_movieIds)]\n",
    "new_user_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we only lost ~300k ratings while droppin alot of redundent movies while extremly low reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for the users, if users with certain number of reviews  will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "118205    9254\n",
       "8405      7515\n",
       "82418     5646\n",
       "121535    5520\n",
       "125794    5491\n",
       "          ... \n",
       "89305       20\n",
       "110463      20\n",
       "96990       20\n",
       "134747      20\n",
       "6526        20\n",
       "Name: count, Length: 138493, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vote_count = user_df.userId.value_counts()\n",
    "user_vote_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most user reviews\n",
      "                             118205 : 9254\n",
      "                               8405 : 7515\n",
      "                              82418 : 5646\n",
      "                             121535 : 5520\n",
      "                             125794 : 5491\n",
      "                              74142 : 5447\n",
      "                              34576 : 5356\n",
      "                             131904 : 5330\n",
      "                              83090 : 5169\n",
      "                              59477 : 4988\n",
      "                             130767 : 4785\n",
      "                              79159 : 4707\n",
      "                               8963 : 4524\n",
      "                              15617 : 4354\n",
      "                              92011 : 4236\n",
      "                              71975 : 4182\n",
      "                              20132 : 4101\n",
      "                              46470 : 4094\n",
      "                              88820 : 4093\n",
      "                              63147 : 3958\n"
     ]
    }
   ],
   "source": [
    "print('Most user reviews')\n",
    "i=20\n",
    "for idx, count in zip(user_vote_count.index ,user_vote_count.to_list()):\n",
    "    print(f\"{idx:35} : {count}\")\n",
    "    i -= 1\n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_vote_filter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([118205,   8405,  82418, 121535, 125794,  74142,  34576, 131904,  83090,\n",
       "        59477,\n",
       "       ...\n",
       "       134897,  50213,  63094, 111821, 103323,  86186,  63958,  28709,  80789,\n",
       "        62328],\n",
       "      dtype='int32', name='userId', length=7491)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_userIds = user_vote_count[user_vote_count>=user_df_vote_filter].index\n",
    "popular_userIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6370818, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_df = new_user_df[new_user_df['userId'].isin(popular_userIds)]\n",
    "new_user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8546, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_movie_df = movie_df[movie_df['movieId'].isin(popular_movieIds)]\n",
    "new_movie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "2571     6980\n",
       "356      6912\n",
       "480      6868\n",
       "1270     6853\n",
       "296      6813\n",
       "         ... \n",
       "797        20\n",
       "51372      17\n",
       "1075       16\n",
       "1133       16\n",
       "795        16\n",
       "Name: count, Length: 8546, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_df.movieId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_movie_df.to_csv(data_dir/'new_movie_df.csv')\n",
    "# new_user_df.to_csv(data_dir/'new_user_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "class MovieRatingDataset2(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "        self.num_users = df.userId.nunique()\n",
    "        self.num_movies = df.movieId.nunique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id = torch.tensor(self.df.iloc[idx][\"userId\"], dtype=torch.int32)\n",
    "        movie_id = torch.tensor(self.df.iloc[idx][\"movieId\"], dtype=torch.int32)\n",
    "        rating = torch.tensor(self.df.iloc[idx][\"rating\"], dtype=torch.float32)\n",
    "        return user_id, movie_id, rating\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MovieRatingData:\n",
    "    user_df: pd.DataFrame\n",
    "    movie_df: pd.DataFrame\n",
    "    movieId2idx: dict\n",
    "    userId2idx: dict\n",
    "    idx2userId: dict\n",
    "    idx2movieId: dict\n",
    "    num_users: int\n",
    "    num_movies: int\n",
    "\n",
    "\n",
    "def load_datasets(user_df, movie_df):\n",
    "    user_df = user_df.copy()\n",
    "    movie_df=movie_df.copy()\n",
    "    \n",
    "    # Create movieId2idx and userId2idx dictionaries\n",
    "    movieId2idx = {\n",
    "        movieId: idx\n",
    "        for idx, movieId in enumerate(user_df['movieId'].value_counts().index.values) # this arranges the movieid from most voted to least voted\n",
    "    }\n",
    "    userId2idx = {\n",
    "        userId: idx\n",
    "        for idx, userId in enumerate(user_df[\"userId\"].value_counts().index.values) # this arranges the movieid from most voted to least voted\n",
    "    }\n",
    "\n",
    "    # Create reverse mappings for idx to user and idx to movies\n",
    "    idx2userId = {idx: userId for userId, idx in userId2idx.items()}\n",
    "    idx2movieId = {idx: movieId for movieId, idx in movieId2idx.items()}\n",
    "\n",
    "    # Map the original movie and user IDs to their corresponding indices\n",
    "    user_df[\"movieId\"] = user_df[\"movieId\"].map(movieId2idx)\n",
    "    user_df[\"userId\"] = user_df[\"userId\"].map(userId2idx)\n",
    "\n",
    "    dataset = MovieRatingDataset2(user_df)\n",
    "    movie_rating_df = MovieRatingData(\n",
    "        user_df=user_df,\n",
    "        movie_df=movie_df,\n",
    "        movieId2idx=movieId2idx,\n",
    "        userId2idx=userId2idx,\n",
    "        idx2movieId=idx2movieId,\n",
    "        idx2userId=idx2userId,\n",
    "        num_movies=len(movieId2idx),\n",
    "        num_users=len(userId2idx),\n",
    "    )\n",
    "    return dataset, movie_rating_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd ,modf =load_datasets(user_df=new_user_df, movie_df=new_movie_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating\n",
       "960      11        1     4.5\n",
       "961      11       10     2.5\n",
       "962      11       19     3.5\n",
       "963      11       32     5.0\n",
       "964      11       39     4.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119145 1 8546\n",
      "8545 0 8546\n"
     ]
    }
   ],
   "source": [
    "print(new_user_df.movieId.unique().max(), new_user_df.movieId.unique().min(), new_user_df.movieId.nunique())\n",
    "print(modf.user_df.movieId.unique().max(), modf.user_df.movieId.unique().min(), modf.user_df.movieId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class SimilarUser():\n",
    "    def __init__(self, x:MovieRatingDataset2, dim = None):\n",
    "        self.x = x\n",
    "        self.pca = None\n",
    "        self.pivot_table = None\n",
    "\n",
    "\n",
    "    def create_pivot_table(self, df:pd.DataFrame):\n",
    "        df = df.copy()\n",
    "        df = df.pivot_table(index='userId', columns='movieId', values='rating',fill_value = 0)\n",
    "        return df\n",
    "        \n",
    "\n",
    "    def do_pca(self, x, n_components=1000):\n",
    "        if self.pca == None:\n",
    "            self.pca = PCA(n_components=n_components)\n",
    "            self.pca.fit(x)\n",
    "            return self.pca.transform(x)\n",
    "        else:\n",
    "            return self.pca.transform(x)\n",
    "        \n",
    "    def similarity(self,idx, x, n=10):\n",
    "        self.pivot_table=self.create_pivot_table(x)\n",
    "        from scipy.sparse import csr_matrix\n",
    "        # convert to sparse matrix for faster calculation of cosine similarities\n",
    "        sparse_matrix = csr_matrix(self.pivot_table.values)\n",
    "        \n",
    "        sim_vec  = cosine_similarity(sparse_matrix, sparse_matrix[idx])\n",
    "        y = sorted(enumerate(sim_vec), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommended_movies_ids = [i[0] for i in y[1:n+1]]\n",
    "        print(recommended_movies_ids)\n",
    "\n",
    "\n",
    "    def similarity2(self,idx, x, n=10):\n",
    "        self.pivot_table=self.create_pivot_table(x)\n",
    "        from scipy.sparse import csr_matrix\n",
    "        # convert to sparse matrix for faster calculation of cosine similarities\n",
    "        sparse_matrix =  coo_matrix((self.x.user_df.rating.values, (self.x.user_df.userId.values, self.x.user_df.movieId.values))).tocsr()\n",
    "\n",
    "        \n",
    "        sim_vec  = cosine_similarity(sparse_matrix, sparse_matrix[idx])\n",
    "        y = sorted(enumerate(sim_vec), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommended_movies_ids = [i[0] for i in y[1:n+1]]\n",
    "        print(recommended_movies_ids)\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 1, 2) (101, 102, 103, 101, 102) (4.5, 3.0, 5.0, 3.5, 2.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Example data: Replace this with your actual data\n",
    "data = [\n",
    "    (1, 101, 4.5),\n",
    "    (2, 102, 3.0),\n",
    "    (3, 103, 5.0),\n",
    "    (1, 101, 3.5),\n",
    "    (2, 102, 2.0)\n",
    "]\n",
    "\n",
    "user_ids, movie_ids, ratings = zip(*data)\n",
    "print(user_ids, movie_ids, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse pivot matrix:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 8. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 5. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 5.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a sparse matrix (similar to a pivot table)\n",
    "sparse_pivot_matrix = coo_matrix((ratings, (user_ids, movie_ids)))\n",
    "\n",
    "print(\"Sparse pivot matrix:\")\n",
    "print(sparse_pivot_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example pivot table\n",
    "data = {\n",
    "    'userId': [1, 2, 3, 1, 2],\n",
    "    'movieId': [101, 102, 103, 101, 102],\n",
    "    'rating': [4.5, 3.0, 5.0, 3.5, 2.0]\n",
    "}\n",
    "\n",
    "pivot_table = pd.pivot_table(pd.DataFrame(data), values='rating', index='userId', columns='movieId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  101  102  103\n",
       "userId                \n",
       "1        4.0  NaN  NaN\n",
       "2        NaN  2.5  NaN\n",
       "3        NaN  NaN  5.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       4      101     4.0\n",
       "1       5      103     3.5"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding new rows\n",
    "new_rows_data = {\n",
    "    'userId': [4, 5],\n",
    "    'movieId': [101, 103],\n",
    "    'rating': [4.0, 3.5]\n",
    "}\n",
    "\n",
    "new_rows_df = pd.DataFrame(new_rows_data)\n",
    "new_rows_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15461/91659949.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpivot_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpivot_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_rows_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Updated pivot table:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "pivot_table = pivot_table.append(new_rows_df.pivot_table(values='rating', index='userId', columns='movieId'))\n",
    "print(\"Updated pivot table:\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SimilarUser(modf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 5, 13, 12, 11, 4, 25, 7, 37]\n",
      "CPU times: user 6.44 s, sys: 732 ms, total: 7.17 s\n",
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = ss.similarity(1,ss.x.user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 5, 13, 12, 11, 4, 25, 7, 37]\n",
      "CPU times: user 5.63 s, sys: 509 ms, total: 6.14 s\n",
      "Wall time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = ss.similarity2(1,ss.x.user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.5, 2.5, 3.5, 5. , 2. , 4. , 3. , 0.5, 1.5, 1. ], dtype=float32), 10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_df.rating.unique(),new_user_df.rating.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_df.movieId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = new_user_df.pivot_table(values='rating', index=\"userId\", columns='movieId')\n",
    "pt.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1000)\n",
    "user_sim = pca.fit_transform(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 1000\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "information_retained = cumulative_explained_variance_ratio[n_components - 1]\n",
    "information_loss = 1 - information_retained\n",
    "\n",
    "print(f\"Information retained with {n_components} components: {information_retained:.2f}\")\n",
    "print(f\"Information loss: {information_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class MovieRatingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        \n",
    "        users = df.userId.sort_values().unique()\n",
    "        movies = df.movieId.sort_values().unique()\n",
    "        \n",
    "        self.num_users = len(users)\n",
    "        self.num_movies = len(movies) \n",
    "        \n",
    "        self.userId2idx = {userId:idx for idx, userId in enumerate(users)}\n",
    "        self.movieId2idx = {movieId:idx for idx, movieId in enumerate(movies)}\n",
    "        \n",
    "        self.idx2userId = {idx:userId for userId, idx in self.userId2idx.items()}\n",
    "        self.idx2movieId = {idx:movieId for movieId, idx in self.movieId2idx.items()}\n",
    "        \n",
    "        self.df.movieId =  self.df.movieId.map(self.movieId2idx)\n",
    "        self.df.userId =  self.df.userId.map(self.userId2idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id = torch.tensor(self.df.iloc[idx]['userId'], dtype=torch.int32)\n",
    "        movie_id = torch.tensor(self.df.iloc[idx]['movieId'], dtype=torch.int32)\n",
    "        rating = torch.tensor(self.df.iloc[idx]['rating'], dtype=torch.float32)\n",
    "        return user_id, movie_id, rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "class RecommenderModel(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim, model_path:Path=None):\n",
    "        super(RecommenderModel, self).__init__()\n",
    "        self.model_path = model_path\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "        self.user_embedding_bias = nn.Embedding(num_users, 1)\n",
    "        self.movie_embedding_bias = nn.Embedding(num_movies, 1)\n",
    "        self.out = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        \n",
    "        self.user_embedding.weight.data.uniform_(0, 0.05)\n",
    "        self.movie_embedding.weight.data.uniform_(0, 0.05)\n",
    "        self.user_embedding_bias.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.movie_embedding_bias.weight.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "    def forward(self, user_ids, movie_tags, debug=False):\n",
    "   \n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        movie_emb = self.movie_embedding(movie_tags)\n",
    "        \n",
    "        user_emb_bias = self.user_embedding_bias(user_ids)\n",
    "        movie_emb_bias = self.movie_embedding_bias(movie_tags)\n",
    "\n",
    "        interaction = (user_emb * movie_emb) + user_emb_bias + movie_emb_bias\n",
    "        output = self.out(interaction) \n",
    "        if debug:\n",
    "            print('user_emb.shape   : ',user_emb.shape)\n",
    "            print('movie_emb.shape  : ',movie_emb.shape)\n",
    "            print('interaction.shape: ',interaction.shape)\n",
    "            \n",
    "            print('user_emb_bias.shape  : ',user_emb_bias.shape)\n",
    "            print('movie_emb_bias.shape: ',movie_emb_bias.shape)\n",
    "            \n",
    "            print('output.shape     :',output.shape)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def load_model(self, model_path=None):\n",
    "        if model_path is None:\n",
    "            model_path = self.model_path\n",
    "        \n",
    "        try:\n",
    "            self.load_state_dict(torch.load(model_path))\n",
    "            print('Model weights loaded.')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f'Weights not found. {e}')\n",
    "        except RuntimeError as e:\n",
    "            raise(e)\n",
    "            \n",
    "            \n",
    "    def save_model(self, model_path=None):\n",
    "        if model_path is None:\n",
    "            model_path = self.model_path\n",
    "        torch.save(self.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderModel(10, 45, 8)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = model(torch.randint(1,10,(32,1)).squeeze(), torch.randint(1,45,(32,1)).squeeze(), debug=True).squeeze()\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_function, num_epochs=10, device='cpu', data_percent=1.0, steps_per_epoch=None):\n",
    "    model.to(device)\n",
    "    print(f'{model.__class__.__name__} Running on: {device}')\n",
    "\n",
    "    data_size = int(data_percent * len(dataloader))\n",
    "    dataloader = iter(dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        total_mse = 0.0\n",
    "        total_mae = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        epoch_progress = tqdm(range(data_size), desc=f\"Epoch [{epoch+1:2}/{num_epochs:2}]\")\n",
    "        \n",
    "        if steps_per_epoch is not None:\n",
    "            epoch_progress = tqdm(range(steps_per_epoch), desc=f\"Epoch [{epoch+1:2}/{num_epochs:2}]\")\n",
    "\n",
    "        last_update_time = time.time() - 1.0  # Initialize to ensure the first update\n",
    "        \n",
    "        for _ in epoch_progress:\n",
    "            try:\n",
    "                batch = next(dataloader)\n",
    "            except StopIteration:\n",
    "                print(\"Dataloader is exhausted. Resetting or stopping training.\")\n",
    "                # You might want to break the loop or take some other action here\n",
    "                break\n",
    "\n",
    "            user_ids, movie_ids, ratings = batch\n",
    "\n",
    "            \n",
    "            user_ids = user_ids.to(device)\n",
    "            movie_ids = movie_ids.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(user_ids, movie_ids).squeeze()\n",
    "            \n",
    "            \n",
    "            loss = loss_function(outputs, ratings)\n",
    "            mse = F.mse_loss(outputs, ratings)\n",
    "            mae = F.l1_loss(outputs, ratings)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_mse += mse.item()\n",
    "            total_mae += mae.item()\n",
    "            total_samples += len(ratings)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            formatted_loss = f\"{loss.item():.8f}\"\n",
    "            formatted_mse = f\"{mse.item():.8f}\"\n",
    "            formatted_mae = f\"{mae.item():.8f}\"\n",
    "            \n",
    "            current_time = time.time()\n",
    "            if current_time - last_update_time > epoch_progress.mininterval:\n",
    "                epoch_progress.set_postfix({\"Loss\": formatted_loss, \"MSE\": formatted_mse, \"MAE\": formatted_mae})\n",
    "                epoch_progress.update()\n",
    "                last_update_time = current_time\n",
    "\n",
    "            if steps_per_epoch is not None and _ + 1 >= steps_per_epoch:\n",
    "                break\n",
    "\n",
    "        # epoch_progress.close()\n",
    "        average_loss = total_loss / min(data_size, steps_per_epoch) if steps_per_epoch is not None else total_loss / data_size\n",
    "        average_mse = total_mse / min(data_size, steps_per_epoch) if steps_per_epoch is not None else total_mse / data_size\n",
    "        average_mae = total_mae / min(data_size, steps_per_epoch) if steps_per_epoch is not None else total_mae / data_size\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1:2}/{num_epochs:2}] - Average Loss: {average_loss:.8f} - Average MSE: {average_mse:.8f} - Average MAE: {average_mae:.8f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size for DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "# train\n",
    "dataset = MovieRatingDataset(new_user_df)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print('users : ',dataset.num_users)\n",
    "print('movies: ',dataset.num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate through the DataLoader during training\n",
    "# for batch in dataloader:\n",
    "\n",
    "#     user_ids, movie_tags, ratings = batch\n",
    "    \n",
    "#     print(\"User IDs:\", user_ids, user_ids.shape)\n",
    "#     print(\"Movie ids:\", movie_tags, movie_tags.shape)\n",
    "#     print(\"Ratings:\", ratings, ratings.shape)\n",
    "#     break  # only print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model, optimizer, and loss function\n",
    "num_users = dataset.num_users  # actual number of users #\n",
    "num_movies = dataset.num_movies  # actual number of tokens\n",
    "dim = 8\n",
    "\n",
    "model = RecommenderModel(num_users, num_movies, dim)\n",
    "\n",
    "# print(f'{num_users=}')\n",
    "# print(f'{num_movies=}')\n",
    "# print(f'{model=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=0.0015)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path\n",
    "model_dir = cur_dir.parent/'models'\n",
    "model_path = model_dir/'model.pth'\n",
    "model.model_path=model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model is exists\n",
    "# model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'\n",
    "num_epochs = 10\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, dataloader,  optimizer, loss_function, num_epochs=num_epochs, device=device, data_percent=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_movie_embedding = model.movie_embedding.weight.data.cpu().numpy()\n",
    "trained_movie_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 10\n",
    "kmeans = KMeans(n_clusters=clusters,random_state=0).fit(trained_movie_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in range(clusters):\n",
    "    print('Cluster: ',cluster)\n",
    "    movs = []\n",
    "    \n",
    "    for movidx in np.where(kmeans.labels_==cluster)[0]:\n",
    "        # print(movidx)\n",
    "        movieid = dataset.idx2movieId[movidx]\n",
    "        movie_title = movie_df[movie_df.movieId==movieid].title.values\n",
    "        movs.append(movie_title)\n",
    "        print('\\t',movie_title)\n",
    "        \n",
    "        if len(movs)==15:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def find_similar_movies(target_movie_embedding, all_movie_embeddings, top_n=5):\n",
    "    with torch.inference_mode():\n",
    "        # Calculate cosine similarity\n",
    "        similarity_scores = F.cosine_similarity(target_movie_embedding, all_movie_embeddings, dim=1)\n",
    "        \n",
    "        # Sort movies based on similarity scores\n",
    "        sorted_indices = torch.argsort(similarity_scores, descending=True)\n",
    "        \n",
    "        # Get top N similar movie indices\n",
    "        top_indices = sorted_indices[:top_n]\n",
    "        \n",
    "        # return top_indices\n",
    "        return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_movies(idx, n:int=10):\n",
    "    if isinstance(idx, int):\n",
    "        new_movie_id = dataset.movieId2idx[idx]\n",
    "        print(f'Movie : {get_movie_name(idx, new_movie_df)}')\n",
    "\n",
    "    elif isinstance(idx, str):\n",
    "        new_movie_id = dataset.movieId2idx[get_movie_id(idx, new_movie_df)]\n",
    "        print(f'Movie: {idx}')\n",
    "        \n",
    "    \n",
    "    target_movie_embedding = model.movie_embedding(torch.tensor(new_movie_id).to(device)).unsqueeze(0)\n",
    "    all_movie_embeddings = model.movie_embedding.weight.data\n",
    "\n",
    "    # Find similar movies\n",
    "    similar_movie_indices = find_similar_movies(target_movie_embedding, all_movie_embeddings, top_n=n+1)\n",
    "\n",
    "    movies = []\n",
    "    for num, i in enumerate(similar_movie_indices,1):\n",
    "        # print(i)\n",
    "        movies.append(movie_df[movie_df.movieId==dataset.idx2movieId[i.item()]]['title'].values[0])     \n",
    "    return movies      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_df[movie_df.title.str.contains('venger')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_movie_id = int(new_user_df.sample(1).movieId.values[0])\n",
    "print(random_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_movie_name = new_movie_df.sample(1).title.values[0]\n",
    "print(random_movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this as search bar\n",
    "search = 'avenger'\n",
    "new_movie_df[new_movie_df.title.str.lower().str.contains(str(search))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = ['Avengers, The (1998)','Avengers, The (2012)','Captain America: The First Avenger (2011)' ]\n",
    "\n",
    "for i in pp:\n",
    "    display(more_movies(idx = i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction looks perfect. \n",
    "> Note: more the ratings well adjusted the embeddings, movies with less ratings can be seen randomly at any place, because there place in the embedding space is not adjusted enough as highly rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
