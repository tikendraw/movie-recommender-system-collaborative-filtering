{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os, time, random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Callable, List\n",
    "from functools import cache\n",
    "import re\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = Path('.').absolute()\n",
    "data_dir=cur_dir.parent/ 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Movie df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.read_csv(data_dir/'movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.isna().sum() # no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.duplicated().sum() #no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the value counts for each movie title\n",
    "title_value_counts = movie_df['title'].value_counts()\n",
    "\n",
    "# Filter titles that appear more than once\n",
    "duplicate_titles = title_value_counts[title_value_counts > 1].index.tolist()\n",
    "\n",
    "print(duplicate_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some movies have multiple entries with different `movieid` , but it doesn't affect much "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so in genres column there seems to have no spaces bw genres, lets see want unique genres as there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genres = movie_df.genres.apply(lambda x : ' '.join(str(x).split('|'))).values.tolist() # split from |\n",
    "all_genres = ' '.join(set(all_genres)).split() # join all strings and break them into words\n",
    "all_genres = set(all_genres)  # make a set to find unique ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_genres, len(all_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are 20 genres and 1 for movies with no genre (which is (no listed)) which is broken as '(no' and 'listed)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploraing User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(data_dir/'rating.csv', usecols=['userId','movieId','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this columns are using too much precision for very low values, lowering the datatype precision\n",
    "user_df['movieId'] = user_df['movieId'].astype('int32')\n",
    "user_df['userId'] = user_df['userId'].astype('int32')\n",
    "user_df['rating'] = user_df['rating'].astype('float32')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.shape #(20000263,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x: str) -> str:\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)  # Remove punctuation\n",
    "    x = x.lower()  # Convert to lowercase\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'helo#$#@$#%$@%@#$ 44 sir'\n",
    "clean_text(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class MovieRatingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_id = torch.tensor(self.dataframe.iloc[idx]['userId'], dtype=torch.int32)\n",
    "        movie_id = torch.tensor(self.dataframe.iloc[idx]['movieId'], dtype=torch.int32)\n",
    "        rating = self.dataframe.iloc[idx]['rating']        \n",
    "        return user_id, movie_id, rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "class RecommenderModel(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim, model_path:Path=None):\n",
    "        super(RecommenderModel, self).__init__()\n",
    "        self.model_path = model_path\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "        self.out = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "    def forward(self, user_ids, movie_tags, debug=False):\n",
    "        user_ids = user_ids.to(torch.long)  # Convert to Long data type\n",
    "        movie_tags = movie_tags.to(torch.long)  # Convert to Long data type\n",
    "\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        movie_emb = self.movie_embedding(movie_tags)\n",
    "        interaction = user_emb * movie_emb\n",
    "        x = interaction.mean(dim=1)\n",
    "        output = self.out(x)\n",
    "\n",
    "        if debug:\n",
    "            print('user_emb.shape: ',user_emb.shape)\n",
    "            print('movie_emb.shape: ',movie_emb.shape)\n",
    "            print('interaction.shape: ',interaction.shape)\n",
    "            print('output.shape:',output.shape)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def load_model(self, model_path=None):\n",
    "        if model_path is None:\n",
    "            model_path = self.model_path\n",
    "        \n",
    "        try:\n",
    "            self.load_state_dict(torch.load(model_path))\n",
    "            print('Model weights loaded.')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f'Weights not found. {e}')\n",
    "        except RuntimeError as e:\n",
    "            raise(e)\n",
    "            \n",
    "            \n",
    "    def save_model(self, model_path=None):\n",
    "        if model_path is None:\n",
    "            model_path = self.model_path\n",
    "        torch.save(self.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderModel(10, 20, 8)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = model(torch.randint(1,10,(8,1)), torch.randint(1,20,(8,1)))\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, loss_function, num_epochs=10, device='cpu', data_percent=1.0, steps_per_epoch=None):\n",
    "    model.to(device)\n",
    "    print(f'{model.__class__.__name__} Running on: {device}')\n",
    "\n",
    "    data_size = int(data_percent * len(dataloader))\n",
    "    dataloader = iter(dataloader)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        total_mse = 0.0\n",
    "        total_mae = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        epoch_progress = tqdm(range(data_size), desc=f\"Epoch [{epoch+1:2}/{num_epochs:2}]\")\n",
    "        \n",
    "        if steps_per_epoch is not None:\n",
    "            epoch_progress = tqdm(range(steps_per_epoch), desc=f\"Epoch [{epoch+1:2}/{num_epochs:2}]\")\n",
    "\n",
    "        last_update_time = time.time() - 1.0  # Initialize to ensure the first update\n",
    "        \n",
    "        for _ in epoch_progress:\n",
    "            try:\n",
    "                batch = next(dataloader)\n",
    "            except StopIteration:\n",
    "                dataloader = iter(dataloader)\n",
    "                batch = next(dataloader)\n",
    "\n",
    "            user_ids, movie_ids, ratings = batch\n",
    "\n",
    "            user_ids = user_ids.view(-1, 1)\n",
    "\n",
    "            user_ids = user_ids.to(device)\n",
    "            movie_ids = movie_ids.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(user_ids, movie_tags).squeeze()\n",
    "\n",
    "            loss = loss_function(outputs, ratings)\n",
    "            \n",
    "            mse = F.mse_loss(outputs, ratings)\n",
    "            mae = F.l1_loss(outputs, ratings)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_mse += mse.item()\n",
    "            total_mae += mae.item()\n",
    "            total_samples += len(ratings)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            formatted_loss = f\"{loss.item():.8f}\"\n",
    "            formatted_mse = f\"{mse.item():.8f}\"\n",
    "            formatted_mae = f\"{mae.item():.8f}\"\n",
    "            \n",
    "            current_time = time.time()\n",
    "            if current_time - last_update_time > epoch_progress.mininterval:\n",
    "                epoch_progress.set_postfix({\"Loss\": formatted_loss, \"MSE\": formatted_mse, \"MAE\": formatted_mae})\n",
    "                epoch_progress.update()\n",
    "                last_update_time = current_time\n",
    "\n",
    "            if steps_per_epoch is not None and _ + 1 >= steps_per_epoch:\n",
    "                break\n",
    "\n",
    "        # epoch_progress.close()\n",
    "        average_loss = total_loss / min(data_size, steps_per_epoch) if steps_per_epoch is not None else total_loss / data_size\n",
    "        average_mse = total_mse / min(data_size, steps_per_epoch) if steps_per_epoch is not None else total_mse / data_size\n",
    "        average_mae = total_mae / min(data_size, steps_per_epoch) if steps_per_epoch is not None else total_mae / data_size\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1:2}/{num_epochs:2}] - Average Loss: {average_loss:.8f} - Average MSE: {average_mse:.8f} - Average MAE: {average_mae:.8f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.userId.max(), user_df.userId.min(), user_df.userId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.movieId.max(), user_df.movieId.min(), user_df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size for DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "# train\n",
    "dataset = MovieRatingDataset(user_df)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Iterate through the DataLoader during training\n",
    "for batch in dataloader:\n",
    "    user_ids, movie_tags, ratings = batch\n",
    "    print(\"User IDs:\", user_ids)\n",
    "    print(\"Movie ids:\", movie_tags)\n",
    "    print(\"Ratings:\", ratings)\n",
    "    break  # only print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.userId.nunique(),movie_df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max userid value: ',user_df.userId.max())\n",
    "print('unique userid: ',user_df.userId.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max movieid value: ',movie_df.movieId.max())\n",
    "print('unique movieid: ',movie_df.movieId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model, optimizer, and loss function\n",
    "num_users = user_df.userId.nunique()  # actual number of users\n",
    "num_movies = movie_df.movieId.nunique() # actual number of tokens\n",
    "dim = 8\n",
    "model = RecommenderModel(num_users, num_movies, dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1  # Set the number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path\n",
    "model_dir = cur_dir.parent/'models'\n",
    "model_path = model_dir/'model.pth'\n",
    "model.model_path=model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model is exists\n",
    "# model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, dataloader,  optimizer, loss_function, num_epochs=2, device=device, data_percent=0.01, steps_per_epoch=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels, predictions = predict(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_movie_embedding = model.movie_embedding.weight.data.cpu().numpy()\n",
    "trained_movie_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trained_movie_embedding[0]\n",
    "a.shape, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10,random_state=0).fit(trained_movie_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cluster in range(10):\n",
    "#     print('Cluster: ',cluster)\n",
    "#     movs = []\n",
    "    \n",
    "#     for movidx in np.where(kmeans.labels_==cluster)[0]:\n",
    "#         print(movidx)\n",
    "#         movie_id, movie_vector, movie_rating = train_dataset.__getitem__(movidx)\n",
    "#         print(movie_vector)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def find_similar_movies(target_movie_embedding, all_movie_embeddings, top_n=5):\n",
    "    with torch.inference_mode():\n",
    "        # Calculate cosine similarity\n",
    "        # print(target_movie_embedding.shape)\n",
    "        # print(all_movie_embeddings.shape)\n",
    "        similarity_scores = F.cosine_similarity(target_movie_embedding, all_movie_embeddings, dim=1)\n",
    "        \n",
    "        # print('smilarity score')\n",
    "        # # Sort movies based on similarity scores\n",
    "        sorted_indices = torch.argsort(similarity_scores, descending=True)\n",
    "        \n",
    "        # # Get top N similar movie indices\n",
    "        top_indices = sorted_indices[:top_n]\n",
    "        \n",
    "        # return top_indices\n",
    "        return top_indices\n",
    "\n",
    "target_movie_id = 72  # Replace with the target movie's ID\n",
    "target_movie_embedding = model.movie_embedding(torch.tensor(target_movie_id)).unsqueeze(0)\n",
    "all_movie_embeddings = model.movie_embedding.weight.data\n",
    "print('all_movie_embeddings: ',all_movie_embeddings.shape)\n",
    "\n",
    "# Find similar movies\n",
    "similar_movie_indices = find_similar_movies(target_movie_embedding, all_movie_embeddings, top_n=51)\n",
    "\n",
    "# Print or use the similar movie indices\n",
    "print(\"Similar movie indices:\", similar_movie_indices.shape)\n",
    "print(\"Similar movie indices:\", similar_movie_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_name(idx):\n",
    "    return movie_df[movie_df.movieId==idx].title.values[0]\n",
    "\n",
    "def get_movie_id(movie_name):\n",
    "    return movie_df[movie_df.title==movie_name].movieId.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_movie_name(4)\n",
    "b = get_movie_id(a)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_movies(target_movie_id):\n",
    "    print(get_movie_name(target_movie_id))\n",
    "    target_movie_embedding = model.movie_embedding(torch.tensor(target_movie_id)).unsqueeze(0)\n",
    "    all_movie_embeddings = model.movie_embedding.weight.data\n",
    "\n",
    "    # Find similar movies\n",
    "    similar_movie_indices = find_similar_movies(target_movie_embedding, all_movie_embeddings, top_n=50)\n",
    "    # Print or use the similar movie indices\n",
    "    for num, i in enumerate(similar_movie_indices,1):\n",
    "        try:\n",
    "            print(f\"{i} :{get_movie_name(int(i.numpy()))}\")\n",
    "        except IndexError :\n",
    "            print(f'Error at : {i.numpy()}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_movie_id('War, Inc. (2008)')\n",
    "get_movie_name(get_movie_id('War, Inc. (2008)'))\n",
    "more_movies(get_movie_id('War, Inc. (2008)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.sample(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.movieId.max(), movie_df.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
